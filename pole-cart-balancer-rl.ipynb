{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb7ebc7",
   "metadata": {},
   "source": [
    "<h1> Project Description </h1>\n",
    "\n",
    "Done with equal contributions by:   \n",
    "    <code> Yong Shun Jie U2221938C </code>   \n",
    "    <code> Lim Yan Xuan U2223441H </code>   \n",
    "    <code> Terri Tan Yue Min U2221019C </code>   \n",
    "\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart. In this project, you will need to develop a Reinforcement Learning (RL) agent. The trained agent makes the decision to push the cart to the left or right based on the cart position, velocity, and the pole angle, angular velocity.   \n",
    "  \n",
    "After some research, we decided on two different algorithms for this problem, the <span style=\"color:blue; font-weight:bold\"> Deep Q-learning Neural Network </span> and the <span style=\"color:blue; font-weight:bold\"> Proximial Policy Optimization </span>\n",
    "\n",
    "We present our findings here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d6130",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e14be",
   "metadata": {},
   "source": [
    "After some research, we came to the conclusion of 2 different algorithms for this problem, a <span style=\"color:blue; font-weight:bold\"> Deep Q-Learning Neural Network </span> and <span style=\"color:blue; font-weight:bold\"> Proximial Oplicy Optimization </span>\n",
    "\n",
    "These are the differences between the two reinforcement learning algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561edd4",
   "metadata": {},
   "source": [
    "<b>Deep Q-learning Neural Network </b> :   \n",
    "The Deep Q-learning Neural Netork is value based reinforcement learning algorithm that is similar to the Q-learning algorithm. However, instead of using a formula to greedily find the Q-function of the environment, DQN tries to approximate the Q-function using neural networks.\n",
    "\n",
    "DQN utilizes <b style=\"color:blue;\">Experience Replaying</b> and <b style=\"color:blue;\"> Fixed Q Targets </b> to stabilize its training along with the Q-learning update formula to approximate the Q-function.   \n",
    "\n",
    "The Q-learning update rule :\n",
    "\n",
    "<br/>\n",
    "$$ L_i(\\theta_i) = \\mathbb{E}_{s,a,s',r \\sim D} \\left[ \\left( r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s, a; \\theta_i) \\right)^2 \\right]\n",
    " $$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde690da",
   "metadata": {},
   "source": [
    "<b> Proximial Policy Optimization </b> :    \n",
    "Proximial Policy Optimization is a policy based reinforcement learning algorithm. PPO is a successor to the famous <b style=\"color:blue\">Trust Region Policy Optimization (TRPO) </b>, made by OpenAI to overcome its limitations.\n",
    "\n",
    "PPO tries to optimize the policy function without explicitly estimating the v value function. PPO is designed to not only be more <b style=\"color:blue;\">sample-efficient </b>, it is also more <b style=\"color:blue;\">stable during training</b>.\n",
    "\n",
    "PPO tries to optimize the policy using this function:     \n",
    "<br/>\n",
    "$$ L_t^{CLIP+VF+S}(\\theta) = \\hat{\\mathbb{E}}_t \\left[ L_t^{CLIP}(\\theta) - c_1 L_t^{VF}(\\theta) + c_2 S[\\pi_\\theta](s_t) \\right]\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5c73d",
   "metadata": {},
   "source": [
    "Choice of Reinforcement Learning Algorithm: <b>PPO</b>\n",
    "\n",
    "- In terms of Continuous Action Space, PPO is more suited for continuous action spaces, like controlling the movement of the cart on a horizontal axis. It <b style=\"color:blue;\">eases the task where actions are continuous</b>.\n",
    "- It is <b style=\"color:blue;\">more sample-efficient</b>. As exploration and learning from limited spaces are crucial in the pole cart balancing task, the efficiency from PPO can lead to faster convergence and better performance.\n",
    "- Since tasks like pole cart balancing requires precise and consistent control to maintain balance, PPO is designed to be <b style=\"color:blue\">more stable during training</b>.\n",
    "- PPO's adaptive step sizes and clipped surrogate objective makes it <b style=\"color:blue\">more adaptable to different environments</b>. The flexibility benefits the fine-tuning of the balancing behaviour of the cart in response to the changes in environment and task requirements.\n",
    "\n",
    "- While both Deep Q-Learning and PPO have its strengths and weakness, PPO's suitability for continuous action spaces, sample efficiency, adaptability and stability makes it a better choice for the pole cart balancing task when making a decision in terms of the Reinforcement Learning Algorithm used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198126b",
   "metadata": {},
   "source": [
    "<h1> Installing dependencies </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc27df65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from gymnasium) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from gymnasium) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.1.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.7.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.9.0.80)\n",
      "Requirement already satisfied: pygame in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.5.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.65.0)\n",
      "Requirement already satisfied: rich in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.7.0)\n",
      "Requirement already satisfied: shimmy[atari]~=1.3.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (9.4.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from shimmy[atari]~=1.3.0->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2023.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from moviepy) (1.24.3)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from moviepy) (2.26.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shun jie\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "!pip install stable-baselines3[extra]\n",
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b4f02",
   "metadata": {},
   "source": [
    "<h1> Creating the gym environment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff789ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shun Jie\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b731552",
   "metadata": {},
   "source": [
    "We use ```gym.make()``` to create a simulation of the environment.   \n",
    "The environment has <span style=\"color: blue; font-weight: bold;\">4 actions</span> that we can take and <span style=\"color: blue;font-weight: bold;\">2 distinct observations</span> for our agent.   \n",
    "\n",
    "Observation Space contains ```[base position, base velocity, pole angle, pole angular velocity]```.    \n",
    "Action Space contains ```[left, right]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc3c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space : 4\n",
      "Action Space : 2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "print(\"Observation Space : {}\".format(env.observation_space.shape[0]))\n",
    "print(\"Action Space : {}\".format(env.action_space.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8846e51",
   "metadata": {},
   "source": [
    "To test our envrionment, we will iterate through <b style=\"color:blue;\">10 episodes</b>.   \n",
    "Taking random actions i.e <code> [left, right] </code> we render the environment until the episode length reaches <code> 500 </code> or the pole angular velocity goes beyond the bounds of ``` ~ -0.418 rad (-24°) and ~ 0.418 rad (24°) ```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebc0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 score : 38.0\n",
      "Episode 2 score : 21.0\n",
      "Episode 3 score : 17.0\n",
      "Episode 4 score : 29.0\n",
      "Episode 5 score : 15.0\n",
      "Episode 6 score : 17.0\n",
      "Episode 7 score : 11.0\n",
      "Episode 8 score : 11.0\n",
      "Episode 9 score : 25.0\n",
      "Episode 10 score : 15.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "env.reset()\n",
    "\n",
    "for episode in range (1, episodes + 1):\n",
    "    observation = env.reset()\n",
    "    score = 0\n",
    "    \n",
    "    while True:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward;\n",
    "        if terminated or truncated:\n",
    "            break;\n",
    "     \n",
    "    print(\"Episode {} score : {}\".format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144789b",
   "metadata": {},
   "source": [
    "<h1> Building and Training the model </h1>\n",
    "<p>From the Stable Baselines library, we will be using the PPO (<b style=\"color:blue;\">Proximal Policy Optimization</b>) algorithm. MlpPolicy which refers to <b style=\"color:blue;\"> Multi-Layer Perceptron Policy </b> is used as it is a neural network policy that contains multiple layers that is suitable for discrete action spaces and is able to handle a wide range of environments.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63f9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13a93ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745033ea",
   "metadata": {},
   "source": [
    "To train the model, we will conduct training over 30,000 steps. From the output, we will examine <b style=\"color:blue;\">ep_len_mean</b>,<b style=\"color:blue\">ep_rew_mean</b> and <b style=\"color:blue\">explained_variance</b>. A higher value for <b style=\"color:blue\">ep_len_mean</b> indicates a more successful average duration of episodes. Similarly, a higher <b style=\"color:blue\">ep_rew_mean</b> signifies a better average reward for each episode. For <b style=\"color:blue\">explained_variance</b>, we aim for a higher value closer to 1, as it indicates more accurate predictions. We chose 30,000 steps because it yields the best learning value output after multiple training sessions, allowing the agent to interact more effectively with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd467a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21       |\n",
      "|    ep_rew_mean     | 21       |\n",
      "| time/              |          |\n",
      "|    fps             | 765      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.9        |\n",
      "|    ep_rew_mean          | 25.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009482385 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.000349    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | 31.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010703884 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.38        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 42.6         |\n",
      "|    ep_rew_mean          | 42.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 536          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089532025 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0225      |\n",
      "|    value_loss           | 47.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 54.5        |\n",
      "|    ep_rew_mean          | 54.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009976197 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.9         |\n",
      "|    ep_rew_mean          | 67.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093151005 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    value_loss           | 59.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.6        |\n",
      "|    ep_rew_mean          | 85.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005334628 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 103         |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 455         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007513621 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 119         |\n",
      "|    ep_rew_mean          | 119         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008183642 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 135         |\n",
      "|    ep_rew_mean          | 135         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006293455 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 153         |\n",
      "|    ep_rew_mean          | 153         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004609663 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.65        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 169          |\n",
      "|    ep_rew_mean          | 169          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 394          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038411445 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 45           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 187          |\n",
      "|    ep_rew_mean          | 187          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 385          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068666097 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.898        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00885     |\n",
      "|    value_loss           | 7.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 204          |\n",
      "|    ep_rew_mean          | 204          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051485496 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.33         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 220        |\n",
      "|    ep_rew_mean          | 220        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 370        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 82         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00648416 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.515     |\n",
      "|    explained_variance   | -0.644     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.219      |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.00285   |\n",
      "|    value_loss           | 2.31       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x21c864339d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.learn(total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd0cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join(\"Saved Models\", \"PPO\")\n",
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77b25d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 94.359288}, 'TimeLimit.truncated': True, 'terminal_observation': array([1.6738397 , 0.39191687, 0.06172308, 0.1035663 ], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 101.400101}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 0.97589314, -0.0017457 , -0.08285806, -0.165225  ], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 108.763831}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 1.8754412 , -0.0231225 , -0.03925315,  0.19552033], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 116.631899}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.35236737, -0.7644975 ,  0.00732819,  0.29664505], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 124.103099}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.02123193,  0.36682066,  0.07981043, -0.45924643], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 131.561682}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 1.8941244 ,  0.4233139 , -0.01483351, -0.39287195], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 139.088846}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 0.16152012,  0.01616237,  0.02476836, -0.3238995 ], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 143.686422}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 1.6031225 , -0.05393283,  0.12064835,  0.71972007], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 148.066423}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 0.6019867 ,  0.00606465, -0.03623674,  0.17609185], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 152.616156}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 1.190222  ,  0.71930724,  0.03143905, -0.3442654 ], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "vec_env = model.get_env()\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = vec_env.reset()\n",
    "    while True:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "        vec_env.render(\"human\")\n",
    "        if done:\n",
    "            print(\"Info: \", info)\n",
    "            break;\n",
    "\n",
    "#Hack to close window\n",
    "import cv2\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d7600",
   "metadata": {},
   "source": [
    "<h1> Task 1 : Develop an RL agent </h1>\n",
    "<b> For this task, we have to demonstrate the correctness of the implementation through sampling a random state from the environment together with an agent input and output a chosen action on whether it is 0(left) or 1(right). </b>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc04d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "model = PPO.load(\"Saved Models\\PPO\", env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb9328",
   "metadata": {},
   "source": [
    "<p> A new gym environment is created and rendered with rgb_array to visualize the environment. We will use our pre-trained PPO model. A vectorized environment is obtained from the model, enabling the execution of multiple environments simultanteously, each operating independently. This approach significantly accelerates the training process.<br/><br/>\n",
    "After acquiring the environment, we reset the vectorized environment to a random observation state. Using this observation, the PPO model predicts the first action based on the loaded model. The output displays the observation and the predicted action. In this case, applying a force to the left (0) is intended to balance the pole, as determined by the observation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "514183e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation : [[-0.04349744 -0.01592666  0.03937313 -0.03470089]]\n",
      "Action : [1]\n"
     ]
    }
   ],
   "source": [
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "action = model.predict(obs)[0]\n",
    "\n",
    "print(\"Observation : {}\".format(obs))\n",
    "print(\"Action : {}\".format(action))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d393e",
   "metadata": {},
   "source": [
    "<h1> Task 2 : Demonstrate the effectiveness of the RL agent </h1>\n",
    "<br/>\n",
    "<b>For this task, we have to run for 100 episodes, resetting each environment at the beginning and plot the cummulative reward against all episodes. Print the average reward over the 100 episodes.</b>\n",
    "<br/><br/>\n",
    "Using the vectorized environment, we will iterate through 100 episodes. For each episode, the trained learning model will predict an action based on a specific observation. Taking the predicted action for each step, the environment returns four values: <code> new observation </code> , <code> obtained reward </code>, an indicator of whether the episode is completed, and any additional information. A reward will be given after each step and at the end of each episode, and we append that into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "423f6e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 ;   Score: [500.]\n",
      "Episode: 2 ;   Score: [500.]\n",
      "Episode: 3 ;   Score: [500.]\n",
      "Episode: 4 ;   Score: [500.]\n",
      "Episode: 5 ;   Score: [486.]\n",
      "Episode: 6 ;   Score: [500.]\n",
      "Episode: 7 ;   Score: [500.]\n",
      "Episode: 8 ;   Score: [500.]\n",
      "Episode: 9 ;   Score: [361.]\n",
      "Episode: 10 ;   Score: [500.]\n",
      "Episode: 11 ;   Score: [500.]\n",
      "Episode: 12 ;   Score: [500.]\n",
      "Episode: 13 ;   Score: [500.]\n",
      "Episode: 14 ;   Score: [438.]\n",
      "Episode: 15 ;   Score: [500.]\n",
      "Episode: 16 ;   Score: [500.]\n",
      "Episode: 17 ;   Score: [500.]\n",
      "Episode: 18 ;   Score: [500.]\n",
      "Episode: 19 ;   Score: [500.]\n",
      "Episode: 20 ;   Score: [500.]\n",
      "Episode: 21 ;   Score: [500.]\n",
      "Episode: 22 ;   Score: [500.]\n",
      "Episode: 23 ;   Score: [500.]\n",
      "Episode: 24 ;   Score: [500.]\n",
      "Episode: 25 ;   Score: [500.]\n",
      "Episode: 26 ;   Score: [500.]\n",
      "Episode: 27 ;   Score: [500.]\n",
      "Episode: 28 ;   Score: [500.]\n",
      "Episode: 29 ;   Score: [500.]\n",
      "Episode: 30 ;   Score: [500.]\n",
      "Episode: 31 ;   Score: [500.]\n",
      "Episode: 32 ;   Score: [500.]\n",
      "Episode: 33 ;   Score: [500.]\n",
      "Episode: 34 ;   Score: [500.]\n",
      "Episode: 35 ;   Score: [500.]\n",
      "Episode: 36 ;   Score: [500.]\n",
      "Episode: 37 ;   Score: [500.]\n",
      "Episode: 38 ;   Score: [500.]\n",
      "Episode: 39 ;   Score: [500.]\n",
      "Episode: 40 ;   Score: [500.]\n",
      "Episode: 41 ;   Score: [500.]\n",
      "Episode: 42 ;   Score: [500.]\n",
      "Episode: 43 ;   Score: [500.]\n",
      "Episode: 44 ;   Score: [500.]\n",
      "Episode: 45 ;   Score: [500.]\n",
      "Episode: 46 ;   Score: [500.]\n",
      "Episode: 47 ;   Score: [500.]\n",
      "Episode: 48 ;   Score: [500.]\n",
      "Episode: 49 ;   Score: [500.]\n",
      "Episode: 50 ;   Score: [500.]\n",
      "Episode: 51 ;   Score: [500.]\n",
      "Episode: 52 ;   Score: [500.]\n",
      "Episode: 53 ;   Score: [500.]\n",
      "Episode: 54 ;   Score: [500.]\n",
      "Episode: 55 ;   Score: [500.]\n",
      "Episode: 56 ;   Score: [337.]\n",
      "Episode: 57 ;   Score: [500.]\n",
      "Episode: 58 ;   Score: [500.]\n",
      "Episode: 59 ;   Score: [500.]\n",
      "Episode: 60 ;   Score: [500.]\n",
      "Episode: 61 ;   Score: [500.]\n",
      "Episode: 62 ;   Score: [500.]\n",
      "Episode: 63 ;   Score: [500.]\n",
      "Episode: 64 ;   Score: [500.]\n",
      "Episode: 65 ;   Score: [500.]\n",
      "Episode: 66 ;   Score: [500.]\n",
      "Episode: 67 ;   Score: [500.]\n",
      "Episode: 68 ;   Score: [500.]\n",
      "Episode: 69 ;   Score: [500.]\n",
      "Episode: 70 ;   Score: [500.]\n",
      "Episode: 71 ;   Score: [500.]\n",
      "Episode: 72 ;   Score: [500.]\n",
      "Episode: 73 ;   Score: [500.]\n",
      "Episode: 74 ;   Score: [500.]\n",
      "Episode: 75 ;   Score: [500.]\n",
      "Episode: 76 ;   Score: [500.]\n",
      "Episode: 77 ;   Score: [500.]\n",
      "Episode: 78 ;   Score: [500.]\n",
      "Episode: 79 ;   Score: [500.]\n",
      "Episode: 80 ;   Score: [478.]\n",
      "Episode: 81 ;   Score: [500.]\n",
      "Episode: 82 ;   Score: [500.]\n",
      "Episode: 83 ;   Score: [500.]\n",
      "Episode: 84 ;   Score: [500.]\n",
      "Episode: 85 ;   Score: [500.]\n",
      "Episode: 86 ;   Score: [500.]\n",
      "Episode: 87 ;   Score: [486.]\n",
      "Episode: 88 ;   Score: [500.]\n",
      "Episode: 89 ;   Score: [500.]\n",
      "Episode: 90 ;   Score: [500.]\n",
      "Episode: 91 ;   Score: [472.]\n",
      "Episode: 92 ;   Score: [500.]\n",
      "Episode: 93 ;   Score: [500.]\n",
      "Episode: 94 ;   Score: [500.]\n",
      "Episode: 95 ;   Score: [500.]\n",
      "Episode: 96 ;   Score: [500.]\n",
      "Episode: 97 ;   Score: [500.]\n",
      "Episode: 98 ;   Score: [500.]\n",
      "Episode: 99 ;   Score: [500.]\n",
      "Episode: 100 ;   Score: [500.]\n",
      "[array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([486.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([361.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([438.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([337.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([478.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([486.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([472.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "episodes = 100\n",
    "vec_env = model.get_env()\n",
    "cumilative_rewards = []\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    score = 0\n",
    "    obs = vec_env.reset()\n",
    "    \n",
    "    while True:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "        if done:\n",
    "            break;\n",
    "    print('Episode:', episode, ';   Score:', score)\n",
    "    cumilative_rewards.append(score)\n",
    "\n",
    "print(cumilative_rewards)\n",
    "\n",
    "#Hack to close window\n",
    "import cv2\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef050f",
   "metadata": {},
   "source": [
    "<h3> Plotting our rewards </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593b49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b27574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABz50lEQVR4nO3de1xU1fo/8M/cQRTkoiDe7zfEFMs0jzdQM82yOnrUytRTVmpiat5N/WqYpZZWejTTU9qPThfLbh4lhTK0FCXR7HLKvAViXkAUB5hZvz9gb2ZgZpxhNrIZPu/Xi1exZ8/Mmi17z7Of9ay1NEIIASIiIiIfpa3qBhARERFVJgY7RERE5NMY7BAREZFPY7BDREREPo3BDhEREfk0BjtERETk0xjsEBERkU9jsENEREQ+jcEOERER+TQGO6R6R48exbhx49C8eXP4+fmhdu3a6Nq1K1asWIFLly5VdfNcWrRoETQaTYWe+8UXX2DRokUOH2vWrBkee+yxijesgvr27QuNRiP/+Pn5oUOHDli6dCkKCgpueXsqQ3JyMjQaDZKTkxV5PSEE3n33XfTv3x/BwcEwmUxo0aIFJk2ahDNnzijyHkrasmWL3b9x2Z+KHBelj6m7+vbti759+97S9yR10ld1A4hc2bhxI55++mm0bdsWM2fORIcOHVBYWIhDhw5h/fr12L9/P7Zv317VzawUX3zxBV5//XWHAc/27dsRGBh46xsFoEWLFti2bRsA4MKFC3jzzTexYMECnD59Ghs2bKiSNqmV1WrF6NGj8d5772HUqFHYsmULgoKCcPToUbz00kt499138dlnn+Guu+6q6qaWs3nzZrRr167c9g4dOnj8Wl27dsX+/fsr9FwiJTDYIdXav38/nnrqKQwYMAAff/wxTCaT/NiAAQMwffp07Ny5swpbWHW6dOlSZe/t7++PO++8U/598ODB6NChA/79739jzZo18PPzq7K2uSs/Px/+/v6V/j4vvvgi3nvvPSxfvhyzZs2St/ft2xcjR45E9+7d8eCDD+Knn35C3bp1K709kuvXr6NWrVou94mKikK3bt0Ueb/AwEC7vxmiW43dWKRaL7zwAjQaDTZs2GAX6EiMRiOGDRsm/67RaBxmQcp2+Uhp+j179uDxxx9HaGgoAgMD8eijj+LatWvIysrCiBEjULduXTRo0AAzZsxAYWGh/HxnKfk//vgDGo0GW7Zscfm53nvvPQwcOBANGjSAv78/2rdvj9mzZ+PatWvyPo899hhef/11+XNJP3/88Ue5z3ThwgUYjUYsWLCg3Hv99NNP0Gg0WLNmjbwtKysLEydORKNGjWA0GtG8eXMsXrwYRUVFLtvtjF6vx2233YaCggJcuXJF3i6EwBtvvIHbbrsN/v7+CA4OxkMPPYTff/9d3uf111+HVqtFdna2vG3lypXQaDSYNGmSvM1qtSI4OBjTp0+Xty1evBjdu3dHSEgIAgMD0bVrV2zatAll1zZu1qwZhg4dio8++ghdunSBn58fFi9eLB+fu+++G7Vq1UJYWBiefPJJXL16tdxnPHLkCIYOHYr69evDZDIhMjISQ4YMwdmzZ50el4KCArz00kto3749nnvuuXKPh4eHIyEhAefPn8emTZsAAPHx8QgICEBubm65/UeOHInw8HC7v8X33nsPPXr0QEBAAGrXro1BgwbhyJEjds977LHHULt2bWRkZGDgwIGoU6cOYmNjnbbbExqNBpMnT8a//vUvtGnTBiaTCR06dEBiYqLdfo7Omd9//x3/+Mc/EBkZCZPJhPDwcMTGxiI9PV3ex2q1YsWKFWjXrh1MJhPq16+PRx99tNxxF0JgxYoVaNq0Kfz8/NC1a1d8+eWXDtucm5uLGTNmoHnz5jAajWjYsCHi4+Ptzj8AeP/999G9e3cEBQWhVq1aaNGiBcaPH+/dAaMqw8wOqZLFYsGePXsQExODxo0bV8p7/POf/8QDDzyAxMREHDlyBHPnzkVRURF+/vlnPPDAA3jiiSeQlJSEF198EZGRkXj22WcVed9ff/0V99xzj/zF9tNPP+HFF1/E999/jz179gAAFixYgGvXruGDDz7A/v375ec2aNCg3OvVq1cPQ4cOxb///W8sXrwYWm3pPczmzZthNBoxZswYAMWBzh133AGtVouFCxeiZcuW2L9/P5YuXYo//vgDmzdvrtBnOnnyJOrWrYt69erJ2yZOnIgtW7bgmWeewYsvvohLly5hyZIl6NmzJ3744QeEh4cjLi4OQgh89dVXGDVqFAAgKSkJ/v7+2L17t/xahw4dwpUrVxAXFydv++OPPzBx4kQ0adIEAHDgwAFMmTIF586dw8KFC+3ad/jwYZw4cQLz589H8+bNERAQgPPnz6NPnz4wGAx44403EB4ejm3btmHy5Ml2z7127RoGDBiA5s2b4/XXX0d4eDiysrKwd+9eh4GRJC0tDZcvX8YTTzzhtG7r3nvvhVarxe7duzF9+nSMHz8er776Kv7zn//gn//8p7zflStX8Mknn2DSpEkwGAwAim8G5s+fj3HjxmH+/PlycPW3v/0N33//vV2XUUFBAYYNG4aJEydi9uzZbgW2Foul3H4ajQY6nc5u244dO7B3714sWbIEAQEBeOONNzBq1Cjo9Xo89NBDTl//nnvugcViwYoVK9CkSRP89ddfSE1NtQuYn3rqKWzYsAGTJ0/G0KFD8ccff2DBggVITk7G4cOHERYWBqA48F28eDEmTJiAhx56CGfOnMHjjz8Oi8WCtm3byq93/fp19OnTB2fPnsXcuXMRHR2N48ePY+HChcjIyEBSUhI0Gg3279+PkSNHYuTIkVi0aBH8/Pxw6tQp+fykakgQqVBWVpYAIP7xj3+4/RwA4vnnny+3vWnTpmLs2LHy75s3bxYAxJQpU+z2u//++wUAsWrVKrvtt912m+jatav8+969ewUAsXfvXrv9Tp48KQCIzZs3y9uef/554eo0s1qtorCwUKSkpAgA4ocffpAfmzRpktPnlv1MO3bsEADErl275G1FRUUiMjJSPPjgg/K2iRMnitq1a4tTp07Zvd7LL78sAIjjx487basQQvTp00d07NhRFBYWisLCQpGZmSkWLlwoAIj169fL++3fv18AECtXrrR7/pkzZ4S/v7947rnn5G2NGjUS48ePF0IIYTabRUBAgJg1a5YAILdz2bJlwmAwiLy8PIftslgsorCwUCxZskSEhoYKq9Vqd6x0Op34+eef7Z4za9YsodFoRHp6ut32AQMG2P37Hjp0SAAQH3/8sctjU1ZiYmK54+JIeHi4aN++vfx7165dRc+ePe32eeONNwQAkZGRIYQQ4vTp00Kv15f7G7569aqIiIgQI0aMkLeNHTtWABBvvfWWW+2Wzg9HPzqdzm5fAMLf319kZWXJ24qKikS7du1Eq1at5G1lz5m//vpLABCvvPKK03acOHFCABBPP/203fbvvvtOABBz584VQghx+fJl4efnJ4YPH26337fffisAiD59+sjbEhIShFarFQcPHrTb94MPPhAAxBdffCGEKD0frly5cpOjRdUFu7Goxho6dKjd7+3btwcADBkypNz2U6dOKfa+v//+O0aPHo2IiAjodDoYDAb06dMHAHDixIkKvebgwYMRERFhl5n573//iz///NMu9f7ZZ5+hX79+iIyMRFFRkfwzePBgAEBKSspN3+v48eMwGAwwGAxo0KABlixZgjlz5mDixIl276PRaPDwww/bvU9ERAQ6d+5s150RGxuLpKQkAEBqaiquX7+OZ599FmFhYXJ2JykpSe6ukezZswdxcXEICgqSj+PChQtx8eJFu24xAIiOjkabNm3stu3duxcdO3ZE586d7baPHj3a7vdWrVohODgYs2bNwvr16/Hjjz/e9Bh5Qghhl/kZN24cUlNT8fPPP8vbNm/ejNtvvx1RUVEAiv9ti4qK8Oijj9odXz8/P/Tp08fhqKcHH3zQo3a9/fbbOHjwoN3Pd999V26/2NhYhIeHy7/rdDqMHDkS//vf/5x284WEhKBly5Z46aWXsGrVKhw5cgRWq9Vun7179wJAuVGHd9xxB9q3b4+vvvoKQHFt340bN+TspaRnz55o2rSp3bbPPvsMUVFRuO222+yO26BBg+y62W6//XYAwIgRI/Cf//wH586du8nRIrVjsEOqFBYWhlq1auHkyZOV9h4hISF2vxuNRqfbb9y4och75uXl4W9/+xu+++47LF26FMnJyTh48CA++ugjAMWFsxWh1+vxyCOPYPv27XI3wJYtW9CgQQMMGjRI3u/8+fP49NNP5WBF+unYsSMA4K+//rrpe7Vs2RIHDx7E999/j/fffx+dO3dGQkKCXZ3G+fPnIYRAeHh4ufc6cOCA3fvExcXh9OnT+PXXX5GUlIQuXbqgfv366N+/P5KSkpCfn4/U1FS7Lqzvv/8eAwcOBFA8Yu/bb7/FwYMHMW/ePIfH0VH338WLFxEREVFue9ltQUFBSElJwW233Ya5c+eiY8eOiIyMxPPPP29XP1OW1L3m6m/42rVr+Ouvv+y6aseMGQOTySTXfv344484ePAgxo0bJ+9z/vx5AMVfymWP73vvvVfu37FWrVoej95r3749unXrZvcTExNTbj9Xx/DixYsOX1uj0eCrr77CoEGDsGLFCnTt2hX16tXDM888I3cNSs919G8XGRkpPy79151/y/Pnz+Po0aPljlmdOnUghJCPW+/evfHxxx/LAWWjRo0QFRWF//f//p/jg0Wqx5odUiWdTofY2Fh8+eWXOHv2LBo1anTT55hMJpjN5nLbnV1wK0oabVT2vdwJFPbs2YM///wTycnJcjYHgF2dQkWNGzcOL730EhITEzFy5Ejs2LED8fHxdjUWYWFhiI6OxrJlyxy+RmRk5E3fx8/PTx6lc/vtt6Nfv37o2LEj4uPjMXToUNSuXRthYWHQaDT45ptvHBaX226TimWTkpKwe/duDBgwQN4+f/58fP311zCbzXbBTmJiIgwGAz777DO70V8ff/yxwzY7qpkJDQ1FVlZWue2OtnXq1AmJiYkQQuDo0aPYsmULlixZAn9/f8yePdvhe8bExCA4OBg7duxAQkKCwzbs2LEDVqtV/swAEBwcjPvuuw9vv/02li5dis2bN8PPz0+uaQIg16p88MEH5bIX7n5+pbg6hqGhoU6f17RpU7kw+5dffsF//vMfLFq0CAUFBVi/fr383MzMzHLn/59//ikfA2k/Z+1o1qyZ/HtYWBj8/f3x1ltvOWyT9JoAcN999+G+++6D2WzGgQMHkJCQgNGjR6NZs2bo0aOH089F6sTMDqnWnDlzIITA448/7nDCusLCQnz66afy782aNcPRo0ft9tmzZw/y8vIUbZd08Sz7Xjt27Ljpc6UvnbIBwL/+9a9y+0r7uJvtad++Pbp3747Nmzfj3XffhdlstssGAMVdd8eOHUPLli3L3bV369bNrWCnrNDQUCxfvhznz5/H2rVr5fcRQuDcuXMO36dTp07y8xs0aIAOHTrgww8/RFpamvzFP2DAAFy4cAGrVq1CYGCg3LUAFB9HvV5vF8jl5+fjnXfecbvd/fr1w/Hjx/HDDz/YbX/33XedPkej0aBz585YvXo16tati8OHDzvd12g0YubMmThx4gReeumlco9nZ2djzpw5CA8PtytGBooD1z///BNffPEFtm7diuHDh9sNTR80aBD0ej1+++03h8dXqSHj7vjqq6/kTBNQXNj83nvvoWXLlm7dpABAmzZtMH/+fHTq1Ek+pv379wcAbN261W7fgwcP4sSJE3KQfOedd8LPz0+e+0mSmpparvt56NCh+O233xAaGurwmNkGRhKTyYQ+ffrgxRdfBIByo92oemBmh1SrR48eWLduHZ5++mnExMTgqaeeQseOHVFYWIgjR45gw4YNiIqKwr333gsAeOSRR7BgwQIsXLgQffr0wY8//ojXXnsNQUFBirYrIiICcXFxSEhIQHBwMJo2bYqvvvpK7opypWfPnggODsaTTz6J559/HgaDAdu2bSv3hQtADghefPFFDB48GDqdDtHR0XJ3myPjx4/HxIkT8eeff6Jnz552I1EAYMmSJdi9ezd69uyJZ555Bm3btsWNGzfwxx9/4IsvvsD69evd/oKy9eijj2LVqlV4+eWXMWnSJNx111144oknMG7cOBw6dAi9e/dGQEAAMjMzsW/fPnTq1AlPPfWU/PzY2FisXbsW/v7+8gR7zZs3R/PmzbFr1y4MGzYMen3p5WrIkCFYtWoVRo8ejSeeeAIXL17Eyy+/7DCL5Ex8fDzeeustDBkyBEuXLpVHY/300092+3322Wd44403cP/996NFixYQQuCjjz7ClStX7DIyjsyaNQs//PCD/N+RI0faTSp49epVfPbZZ+X+RgcOHIhGjRrh6aefRlZWVrmgtVmzZliyZAnmzZuH33//HXfffTeCg4Nx/vx5fP/99wgICJCH11fUsWPHHI7aatmypd2ou7CwMPTv3x8LFiyQR2P99NNP5Yaf2zp69CgmT56Mv//972jdujWMRiP27NmDo0ePypmytm3b4oknnsDatWuh1WoxePBgeTRW48aNMW3aNADFmbAZM2Zg6dKl+Oc//4m///3vOHPmDBYtWlSuGys+Ph4ffvghevfujWnTpiE6OhpWqxWnT5/Grl27MH36dHTv3h0LFy7E2bNnERsbi0aNGuHKlSt49dVX7errqJqpwuJoIrekp6eLsWPHiiZNmgij0SgCAgJEly5dxMKFC0V2dra8n9lsFs8995xo3Lix8Pf3F3369BHp6elOR2OVHZEhjZy6cOGC3faxY8eKgIAAu22ZmZnioYceEiEhISIoKEg8/PDD8qidm43GSk1NFT169BC1atUS9erVE//85z/F4cOHyz3XbDaLf/7zn6JevXpCo9EIAOLkyZNCiPKjsSQ5OTnC399fABAbN250eDwvXLggnnnmGdG8eXNhMBhESEiIiImJEfPmzXM62kkijcZy5PPPPxcAxOLFi+Vtb731lujevbsICAgQ/v7+omXLluLRRx8Vhw4dsnvuJ598IgCIAQMG2G1//PHHBQCxZs2acu/31ltvibZt2wqTySRatGghEhISxKZNm+yOkxDFx2rIkCEO2/zjjz+KAQMGCD8/PxESEiImTJggt0UaOfTTTz+JUaNGiZYtWwp/f38RFBQk7rjjDrFlyxaXx0pitVrFtm3bRN++fUXdunWF0WgUzZs3F0899VS5UXG25s6dKwCIxo0bC4vF4nCfjz/+WPTr108EBgYKk8kkmjZtKh566CGRlJQk7+Po79cVV6Oxyv5dARCTJk0Sb7zxhmjZsqUwGAyiXbt2Ytu2bXavWXY01vnz58Vjjz0m2rVrJwICAkTt2rVFdHS0WL16tSgqKpKfZ7FYxIsvvijatGkjDAaDCAsLEw8//LA4c+ZMuWOckJAgGjduLIxGo4iOjhaffvqp6NOnj91oLCGEyMvLE/Pnzxdt27YVRqNRBAUFiU6dOolp06bJo8o+++wzMXjwYNGwYUNhNBpF/fr1xT333CO++eYbt48jqYtGiDIzcBEREblBmvzxtddeq+qmELnEmh0iIiLyaQx2iIiIyKexQJmIiCqEVRBUXTCzQ0RERD6NwQ4RERH5NAY7RERE5NNYswPAarXizz//RJ06dSp1WnUiIiJSjhACV69eRWRkJLRa5/kbBjsoXmfFdiE+IiIiqj7OnDnjcvZ3BjsA6tSpA6D4YHm6MjARERFVjdzcXDRu3Fj+HneGwQ5KF2cMDAxksENERFTN3KwEhQXKRERE5NMY7BAREZFPY7BDREREPo3BDhEREfk0BjtERETk0xjsEBERkU9jsENEREQ+jcEOERER+TQGO0REROTTGOwQERGRT6vSYGfRokXQaDR2PxEREfLjQggsWrQIkZGR8Pf3R9++fXH8+HG71zCbzZgyZQrCwsIQEBCAYcOG4ezZs7f6oxAREZFKVXlmp2PHjsjMzJR/MjIy5MdWrFiBVatW4bXXXsPBgwcRERGBAQMG4OrVq/I+8fHx2L59OxITE7Fv3z7k5eVh6NChsFgsVfFxiIiISGWqfCFQvV5vl82RCCHwyiuvYN68eXjggQcAAP/+978RHh6Od999FxMnTkROTg42bdqEd955B3FxcQCArVu3onHjxkhKSsKgQYNu6Wcp6/K1AlwrKKrQc8Nqm+Bn0Dl9XAiBzJwbsArh8nUC/Q0I9DO43OevPDNuFHoeHCrVRqLqpo7JgKBars+rS9cKcL2C5z8pT6/VIjzQ5HLByOsFRbh0raBS3t+o16J+HT+X++TeKERufqHLfTQaDSKD/Fx+jhuFFvyVZ65QOytT3VpG1DZVTdhR5cHOr7/+isjISJhMJnTv3h0vvPACWrRogZMnTyIrKwsDBw6U9zWZTOjTpw9SU1MxceJEpKWlobCw0G6fyMhIREVFITU11WmwYzabYTaX/iHk5uZWymd7adfPePe70xV6bmiAEXtn9nUaqDz7nx+w/ci5m76OUafFR0/3RFTDIIePv/vdaczdnuHwsZupV8eElJl9Ucvo+M9oxvtH8eFhdimS79FpNXhnwh3o2TLM4eOf/vAnnkk8Asb56jL+ruZYeG8Hh49duGpG/5eTcdVceQHqvHva4/HeLRw+9uOfubjv9X0otNz8j2ZodAO8Nrqrw8duFFrQ96VkZOXe8KqtleGF4Z0wunuTKnnvKg12unfvjrfffhtt2rTB+fPnsXTpUvTs2RPHjx9HVlYWACA8PNzuOeHh4Th16hQAICsrC0ajEcHBweX2kZ7vSEJCAhYvXqzwpynPoNXApPe8p7DAYsXFawU4djYHPVuVv5gKIbDnp2wAxXcLzuL7AosVBRYrfszMdRrspJ+5DKD44q3XOr9TKMtcZMWFq2acvZyPNuF1HO6TdupScRt1Wri4CSGqVgotVlisAsfP5ToNdo6evQIhPD+vqHJYhUChRWD/7xed7nPsXA6umoug0RRfsyrj/ff+nO002Pn2f3+h0CKg1QAGJ+8vRPF1/fuTl5y+16mL1+VApyLfP5VJ4cPqkSoNdgYPHiz/f6dOndCjRw+0bNkS//73v3HnnXcCQLlUnRDCZfrOnX3mzJmDZ599Vv49NzcXjRs3rshHcGnxfVFYfF+Ux8/7578PIulENn67kOcw2Ll4rQA5+YXQaIAfFg6Ev9FxV9Ljbx/C7h/Pw2J1fqdQVPLYrLvb4oneLd1uY4+Er5CZc8Nl99eNQisA4MOneqJTI8fBFlF1M/0/P+DDw2dhcZG2sRT/6eOJ3i0w6+52t6hl5MyJzFwMfvUbZLvIdpwveaxvm3rYPO4ORd//yOnLGP5GKn67kOd0H+mxyf1a4dmBbR3u8+eVfPRcvgeXrxc4/Z6TuuFa1gvAV9P7et94H6GqsC8gIACdOnXCr7/+KtfxlM3QZGdny9meiIgIFBQU4PLly073ccRkMiEwMNDuR01a1qsNAPjtwjWHj/+WXXxSNKzr7zTQASDfURa5CHakQEin9exPQarVkQIaR24UWUr2VdWfGZFXpPPK1U2ExWq125eqVnhgca3MxWsFKChyfM06n2u221dJLevXlt/j6g3HNTlSsCPt60hIgBEAUGgRyHPS3Xb5eoHdvlRMVd9CZrMZJ06cQIMGDdC8eXNERERg9+7d8uMFBQVISUlBz549AQAxMTEwGAx2+2RmZuLYsWPyPtWR9Mf+v2zHdwH/KzkpWrk4KYDiFDoAWCzOAxIpEPL0oiylR11ndqRgx3lARlTdaN0JdkqyPlr236pCcC0DDLrifwtnhbvZV4szO/UrIdgJ9DOgfh0TAOc3sdL1XrrZdcTPoEOtkhtcZ4XUF68x2HGkSoOdGTNmICUlBSdPnsR3332Hhx56CLm5uRg7diw0Gg3i4+PxwgsvYPv27Th27Bgee+wx1KpVC6NHjwYABAUFYcKECZg+fTq++uorHDlyBA8//DA6deokj86qjkozO46Dnd+yr9nt54xbmR2LlNnx7KJcmtlxHOwIIeSsj4mZHfIhUt2BexlTBjtqoNFo5JFQ5510ZUmZHSkoUZp8XXdwE3vpWgEuXy/O+LSoF+DydYJrGeXnOHKZwY5DVVqzc/bsWYwaNQp//fUX6tWrhzvvvBMHDhxA06ZNAQDPPfcc8vPz8fTTT+Py5cvo3r07du3ahTp1SgtiV69eDb1ejxEjRiA/Px+xsbHYsmULdLrqm01oVXJSZObcQJ65qNxQvd/czuwUX5XdqdnxNLMjdU3dcJISNttsZ2aHfIm+5LyyMtipVuoHmnDuSr4c1JQlZXYqoxsLAFrWD8D+3y/KmXlb0jW9YV1/p6NbJSEBRpy7ki93V5UlBUFSUETFqjTYSUxMdPm4RqPBokWLsGjRIqf7+Pn5Ye3atVi7dq3Cras6QbUMCKttwl95Zvx+IQ/RjeraPe5OuhNwt2anOCjx9KLsf5PMjtmmlsefwQ75EKlrytV5VcRgR3XCSzI7UlBTVrZcs1M5mZ1WLjI78jX9JjewABAcIGV2HNf+sGbHMfYvqFTLklRm2bqd/AILzl3Jt9vHGZ3u5rUFcmZHV7FuLLOTYEcqTtZpNU6HURJVR9K54mqyTGsFM6ZUeeqXBDHZDjI7FqvAhTypG6uyMjsltZiOMjvyDazrazoAhJRMZnnpmuMMFTM7jvFbSKWkLqqydTvS78G1DAit7foORM7suChQ9nY0Vr6zYEcqTlbZPA9E3pIzOy4mf5NuIligrB5S95Sjmp2L18ywWAU0GiCsduUECdI1/fTF6ygsc012d9AJAIQEFF/3nWV2pGAnpJI+R3XFbyKVKi1ms6/cl4cn3qQLCyhNobtMt1u8rNlxMvQ8nyOxyEdJ54rLzI6oWMaUKo9UeHz+avmMiJTtCattgr6SMtERgX6oZdShyCpw6uJ1u8c8ua6HBBRndi7frECZmR07DHZUylnKUxq26M4dgDvzgRRVsGbHpHddsyMFQQx2yNdo5ZsIF1M6WJjZURtpSLmjiQVLi5Mrp14HKK5BlYIZ2/KEG4UWnL1cXJrgznVdrtlxVqDMmh2HGOyolPRHf+riNbuU529uFicDpV1T7gyR9Tyz43pSQSkI4rBz8jWlNxHO95EzO6zZUQ0pkMl2kNkpHXZeOfU6EkflCb9fuAYhgCB/A0LdCFCkjI2jzE5+gUW+Jgcz2LHDbyKVahDoB3+DDoUWgdOXSlOe7g47B9zN7FR0nh1p6PnNanaY2SHfIp0r7gw91zLYUQ1pNNalawUwl7luSXU8lZnZAUoLkG1HZNle02+2FBJQmrFxNM+OlNUx6rUIcDG7fk3EYEeltFoNWta3PzEsVoHf/3JvQkHAtmbn5gXK+govF3Gzbiz+iZFvcasWjqOxVKduLYO8wOeFMtkdKdtTFZmd0nqdm4/EAmyCHQfdWJfySut13AmcahJ+E6mY3L9bcjKcvXwdBUVWGPVaNAz2v+nzDZU49NxfHnrubFLB4iDI1dpdRNWRTuN+gTLn2VEPjUaDenUcd2VJdTz1Kz2zU7ruoSj5G3F33jSJ1D2Vk19YbqStFACxC6s8BjsqVnZElnQH0CIswK2LqFyz42KIbMVrdlyvjcVuLPJVnoxyZLCjLnLdTpkiZXkR0ErO7DQNLb5255mL5Pf0ZNAJANT1Lx6NJURxwGOrdKkIg1JN9hkMdlSsbMrTk1k2gcodjXXzeXY4Got8kzs1O3Jmh10JqlK6PlbZbqzKXSpCYtRr0TSkFoDi67rFKvC7B8POAUCv0yKoJOApu2QEJxR0jsGOitkuHCeEkDM8rdw8Kdy5A7VYKlazc7Oh5/kcjUU+yp1aOC4XoU6lI7JKMzsWq5BreCq7QBkAWtgMP//zSj7MRVYYdVo0LgmC3CGN2rqYZx/sSMGPO6O6ahp+E6lYs7Ba0GqAq+YiXLhqLi1kczez40HNToVHY91k6DkzO+RrdO4MPWewo0r1A8tndi7mmWEVgFaDm85KrwR54MmFPLkes7mbpQkSqSbHaWaHwU45DHZUzKTXoUlJtP+/7NITw92qfY9GY1VwbSznQ89LurFYs0M+pjTYYWanunG0ZIRUrBxW23RL/r1a2WR25HnT6rt3TZdI3VRll4yQl4pgsFMOgx2Vk7qyvv/jEq5cL4RGA7QIU7Jmp6KZHdejsUozO/wTI98i1eG4qPu3WXOOwY6aSEtG2C4GWjrHTuXW60ha2tRiynPsuFmaIJGXjGDNjtv4TaRyUpHyf4+fBwA0rOvv9nDuyp1B2fVoLGnoObuxyNe4k9mRgx0WKKuKFNDY1uyUzp5c+V1YQOkN7PlcM46cvlK8zc3SBEnwTWp2mNkpj8GOykknxonMXADuD08EbFc9V340lr+bkwr6M9ghH6NzI2Nq4Tw7qiQVIF++XijfkEmBT/1blNkJ8jfI8/38lHUVgPsjsSShTmt2iru1GOyUx2BH5cr25XpyUrg1aqSCo7FKa3as8uRYttiNRb7KrWCH3ViqFORvgFFffE2SurLkOXZuwUgsSdm6yxZu1mFKSmt2SoMdIQQzOy7wm0jlygY3FcnsOLsoCyEqXrNTUnhssQoUOsgclS4EyswO+RYGO9WXRqMprdspKUzOvsU1O4D9dbxhXX/UMuo9en6Ig8xObn6R/HdXtxYnFSyLwY7K1a1lRFjt0ii9Ypkdxxdl282e1uzYzp/jaEQWJxUkXyUXKDPYqZbkup2SIOe81I11i2p2APvruKf1OkBpzY5tZkdaKqK2SS/Pg0alGOxUA3YnhgfpzpvNs2PbvaXzcOi5Sa+FVHvpqG4nX14ugn9i5Fukc8XiYm0sBjvqJQU10iisbLkbq2oyO55c0yUhDrqxSufYYVbHEX4TVQNS5B9cy+DRpFc3WxvLNgjyNLOj0WhgKglkHA0/56SC5KtKMzvO9+FCoOolz7Vz1YwiixV/5ZWMxrqlNTulwY4npQmSkJJs//UCi3ytLV0X69Z9juqEwU41IJ0YnlbsG25SW1BkF+x4/qfg52JElrmI3Vjkm/QeTCro6U0EVb76gaVz7Vy8VlA6e/ItDBIaBPmhVskUIp5e1wGgjkkv/21JdTtSN1YI63UcYrBTDQyNboC/tQ7D471bePS8m43GslgqntkBSouUHS0ZwdFY5Ku0HhQoaznPjupIi4FmX70hd2HVq3NrZk+WaDQaxMe1xpBODRDTNLhCzy9bt8OlIlzzrAScqkR4oB/emdDd4+fdvGaneLtGU3oB94Q0uaHjAuXibZxnh3yNOzOTl07WyWBfbaQh5udzb9zy2ZNtPdG7pVfPD6llxIWrZjnIkbuxOHuyQzwTfdjNZlCu6OzJEqlmJ7+Ao7Go5pAzO24UKDPWUZ9wm8VAS0di3fpgx1tSITIzO+7hqejDbnYHWtHZkyXOanaEEHK2x8RuLPIx8nnlYmZyZnbUK7wksMnJL8SZS/kAbm1xslKkGiMpoyPV7oQy2HGIZ6IPu9k8O95ekOX1sYrsa3YKLFZIN73M7JCv0WrcyOwIZnbUKtBfL8+ifOxcDoDSAKg6kTM714uXiGBmxzWeij7s5pkd74bHOsvs3CgoDX78OLkV+Zib1cJZrUIO9pnZUR+NRiPX7WRIwU41zOxItTmXy3RjcakIx3gm+jA5s+NkQhBva3akQMZcNtgp6cLSagCDh5MVEqndzWZQts34cNVzdbLtygKqZzeW09FYLFB2iMGOD9PfpEBZmmyw4pmdkm6sMkPPbScU1PBiTz7G3e5hwPOZyenWKBvcVMcC5RCbYKfQYkXujSIArNlxRjXBTkJCQvHcA/Hx8ra8vDxMnjwZjRo1gr+/P9q3b49169bZPc9sNmPKlCkICwtDQEAAhg0bhrNnz97i1quTdKGtrNFYTruxOBKLfJgU7FjdCXYY7KtS2eCmKoaee8t2MdArJXU7Wg0Q6M9JBR1RRbBz8OBBbNiwAdHR0Xbbp02bhp07d2Lr1q04ceIEpk2bhilTpuCTTz6R94mPj8f27duRmJiIffv2IS8vD0OHDoXFUn44dE1zs5qdQmk0VgXvPuVgp6hssMM5dsh3SQXKTjOmNttZsqNOtsGNTqupltmQYJv1saSRWHVrGblEiRNVfirm5eVhzJgx2LhxI4KD7WeS3L9/P8aOHYu+ffuiWbNmeOKJJ9C5c2ccOnQIAJCTk4NNmzZh5cqViIuLQ5cuXbB161ZkZGQgKSmpKj6Oquhsgh3hYOSI96OxioOZ/ALH3Vgcdk6+SCpQtjoZjWWb8WGBsjrZrnBer7apQpOqVjXbzI60vlcwl4pwqsrPxEmTJmHIkCGIi4sr91ivXr2wY8cOnDt3DkII7N27F7/88gsGDRoEAEhLS0NhYSEGDhwoPycyMhJRUVFITU11+p5msxm5ubl2P77ItnvKUXZHsZqdspkdaV0sjsQiH6TzJLNT/b5DawTbzE51HIkFlAY7hRaBM5eu222j8qp0uYjExEQcPnwYBw8edPj4mjVr8Pjjj6NRo0bQ6/XQarV488030atXLwBAVlYWjEZjuYxQeHg4srKynL5vQkICFi9erNwHUSnbIKbIKlA29qi8mh2ui0W+SzqvhCjO4pTNCtiueM4CfXWyDXDqV8N6HaD4+lvLqMP1Agt+u3ANAIMdV6rs2+jMmTOYOnUqtm7dCj8/x39sa9aswYEDB7Bjxw6kpaVh5cqVePrpp2/aRSWEcHmRmTNnDnJycuSfM2fOePVZ1MqgK/3ndZjZKanZ0Ve0ZqdkYi6zi9FYRL7G9ibC0cSC8vxVDHRUy7ZA2bZLq7qR6nZ+y84DwGDHlSrL7KSlpSE7OxsxMTHyNovFgq+//hqvvfYacnJyMHfuXGzfvh1DhgwBAERHRyM9PR0vv/wy4uLiEBERgYKCAly+fNkuu5OdnY2ePXs6fW+TyQSTqfr+gburbGanLIs8qaB3NTvOMzsMdsj36Mp0D5f9M7d6OVknVb5Afz1Mei3MRdZqORJLEhJgxLkr+fjtQnGwwzl2nKuyzE5sbCwyMjKQnp4u/3Tr1g1jxoxBeno6LBYLCgsLoS3zRazT6WAtyUjExMTAYDBg9+7d8uOZmZk4duyYy2CnprC9s3Sc2VGoG6vcaCxp6Dm7scj32AYxjoqULQx2VK94FuXiIKe61uwApRMLnmbNzk1VWWanTp06iIqKstsWEBCA0NBQeXufPn0wc+ZM+Pv7o2nTpkhJScHbb7+NVatWAQCCgoIwYcIETJ8+HaGhoQgJCcGMGTPQqVMnhwXPNY1Wq4FWA1hFaZeVLW8vyjedVJAFyuSDbpYx9XYZFro12kXUwelL19E2IrCqm1JhISWjr6Q/Q2Z2nKvSAuWbSUxMxJw5czBmzBhcunQJTZs2xbJly/Dkk0/K+6xevRp6vR4jRoxAfn4+YmNjsWXLFuh0/KIFioe+FlislZvZcTapoJH/BuR7bDOmjiYWtC1QJvV6eURnnL54HVENg6q6KRUWEmCflQqpzWDHGVUFO8nJyXa/R0REYPPmzS6f4+fnh7Vr12Lt2rWV2LLqS6fVAJbSYea2LNKkgl4GO/lO1sZiZod80U0zO15O6UC3RqCfoVoHOgAQEmA/r04IMztOsajCx7maRVm6KHub2XE+Got/XuR7NBqNPH+Oy8wOR2NRJQsuU6PDmh3n+G3k41ytj+X9aCypZodrY1HN4mqRXdbs0K1SNpNTNvihUgx2fJyUtXFUoOx1zY7ecc2OmZkd8nHS/YGjjClHY9GtYhvcGHVaBLBO0il+G/k46YLruGan5KLs9UKg9oFUPufZIR8nZXZcBTsVvYkgcpftAqYhAUbO2O0Cgx0f5+qi7P1orNLXLrSUBjwcek6+TjplHM2gLJ1r1XFxSapebDM77MJyjcGOj5MzOw4LlJUZjQXYd2VJNTtc9Zx8lc5F4b+cMeVdNlWyuv6lo7HKjswie/w28nEuR2N5mdkx6Uv/fGwnFpSGnvuzG4t8lM5VNxbn2aFbRK/TIqgk4OGEgq4x2PFxOhcFyt6OxtJoNA5HZHE0Fvk6ncsCZe8ypkSekIabc9i5awx2fJyrdLu3mR3A8SzKZhYok49zXaBc/F8GO3QrMNhxD4MdH2fQOZ8PRLoD1VdwNBZgO/zcQYEya3bIR0nJUFfnFYMduhXq1S5eMiKsdvVd0PRWUNVyEaQ8ObPjYOi5Mpmdkm4sm5XPpaHozOyQr5IyO45XPS/+L4MduhWe7tcS9QNNGBrdoKqbomoMdnyc3sVoLIvFu5odwHE3Vn4Bh56Tb5OHnrsqUOZoLLoFohvVRXSjulXdDNVjP4OPq+yaHZPBvhtLCFG6ECi7schHua7Z8b57mIiUxW8jH6fXuTMay5uaHfvRWAUWK6TMvondWOSjtC7n2SnZh5kdItVgsOPjXM0HokRmx79kLRZpiQjbQmXOs0O+ytX8VXJmhzU7RKrBYMfH6V2ujVUyakSB0VjScHPpv1oNYGAan3yUW5kdBjtEqsFgx8e5XC5CydFYJRkd2wkFuSgd+SqXhf/M7BCpDoMdH1eabld+BmWg/Gis0uJkdmGR75JGWjkees6FQInUhsGOj6v8zE5JsFMk1exIw875p0W+q7LPKyJSFr+RfJzLQkqL96OxTC66sYh8lXTOWB2cV1bOs0OkOgx2fJzUReX4DtT72oLS5SKKMzrSqCwOOydf5k5mhzMoE6kHgx0f5yqzo8RF2a/MpIJcF4tqApeZHQY7RKrDbyQfJw0rdzz0vKS2wIsh4v4G+0kFpf9yjh3yZdKEga4yOyxQJlIPBjs+zuBiNJYUAOkVHI1lZs0O1QByxtTBaCwrC5SJVIfBjo9zVbNjqYzRWFwXi2oAec05i4ObCCmzwwJlItXgN5KPk7qoHNfslMygrOikglzxnHyfHOyUP63kbA8zO0TqwWDHx7kaNaJEzY6p7KSCJUEPR2ORL9O5mqxTgSkdiEhZDHZ8nHujsbyo2dGXDXbYjUW+rzTYKf+YlNlhsEOkHvxG8nGlmR3ny0UouTZWfiGXiyDf52q5CA49J1IfBjs+ztWq50rOs2Musu/GYs0O+TJXUzpwUkEi9VFNsJOQkACNRoP4+Hi77SdOnMCwYcMQFBSEOnXq4M4778Tp06flx81mM6ZMmYKwsDAEBARg2LBhOHv27C1uvXpV9mgsaT6d/AJp6HnJPDtG1fxpESlOyuw4HHrO5SKIVEcV30gHDx7Ehg0bEB0dbbf9t99+Q69evdCuXTskJyfjhx9+wIIFC+Dn5yfvEx8fj+3btyMxMRH79u1DXl4ehg4dCovFcqs/hiq5rtlRYjSWNPS8ZDQWVz2nGsBVgbKU7dF5UfhPRMrSV3UD8vLyMGbMGGzcuBFLly61e2zevHm45557sGLFCnlbixYt5P/PycnBpk2b8M477yAuLg4AsHXrVjRu3BhJSUkYNGjQrfkQKuZyNJYikwoWP9diFSi0WNmNRTWCWwXKzOwQqUaVZ3YmTZqEIUOGyMGKxGq14vPPP0ebNm0waNAg1K9fH927d8fHH38s75OWlobCwkIMHDhQ3hYZGYmoqCikpqY6fU+z2Yzc3Fy7H19VOs+O88nPlMjsAMUjsW7IC4FW+Z8WUaXRuxp6zpodItWp0m+kxMREHD58GAkJCeUey87ORl5eHpYvX467774bu3btwvDhw/HAAw8gJSUFAJCVlQWj0Yjg4GC754aHhyMrK8vp+yYkJCAoKEj+ady4sbIfTEV0bhQoezXPjr70T+hGodVm6DkzO+S7tK4yOwx2iFSnyrqxzpw5g6lTp2LXrl12NTgSa8kd03333Ydp06YBAG677TakpqZi/fr16NOnj9PXFkJA4yKFPGfOHDz77LPy77m5uT4b8Lis2bF4X7Oj0Whg0mthLrKWZHa4Nhb5PncyO5xBmUg9qiyzk5aWhuzsbMTExECv10Ov1yMlJQVr1qyBXq9HaGgo9Ho9OnToYPe89u3by6OxIiIiUFBQgMuXL9vtk52djfDwcKfvbTKZEBgYaPfjqyp7NBZgP/xcLlDWsxuLfJfWxWgsC1c9J1KdKvtGio2NRUZGBtLT0+Wfbt26YcyYMUhPT4fJZMLtt9+On3/+2e55v/zyC5o2bQoAiImJgcFgwO7du+XHMzMzcezYMfTs2fOWfh61MrhcG0vqxvLuz8B2YsEbBezGIt+nc5ExlbuxWKBMpBpV1o1Vp04dREVF2W0LCAhAaGiovH3mzJkYOXIkevfujX79+mHnzp349NNPkZycDAAICgrChAkTMH36dISGhiIkJAQzZsxAp06dyhU811SVPYMyYDPXTqFFHoLub2SwQ77LZbDD5SKIVKfKh567Mnz4cKxfvx4JCQl45pln0LZtW3z44Yfo1auXvM/q1auh1+sxYsQI5OfnIzY2Flu2bIFOxy9bwHnNjhBCsZle/WwWA+Wq51QTuLPALoMdIvVQVbAjZWxsjR8/HuPHj3f6HD8/P6xduxZr166txJZVX85qdmx/9TazU7ryuZULgVKNIJ0zVgY7RNUCv5F8nLPMjm23lteZnZJi5DxzoRxEmVizQz5MKlB2lNnh2lhE6sNgx8c5m2fHNvjxZgZloLQb68r1Qptt/NMi3yXNTeVq1XMOPSdSD34j+Ti9kwJl2ztS72t2iv+MpGBHowGMXo7wIlIzeei5iwJlLUdjEakGv5F8nLNCSovFNrOjTIHylesFxb/rdS4ndSSq7lxN1mlRYGZyIlIWgx0fp3cyz44U/Gg03k9+Jo28ulyS2WEXFvk6rRvBDjM7ROrBbyUfJ4/GclKzo0RdgTSnzpX84mDHn8XJ5OP0bgw997YWjoiUw7PRx91sNJYSI0akFc5zpG4sBjvk46TzxlGBculyEbe0SUTkAk9HH+e0ZkfBu0+pG0vK7HDYOfk6Z6McAWZ2iNSIZ6OPc7Y6c6FFublAyg49Z80O+Tpp3SuHmR15uYhb2iQicoGno4+7eWZHiWCn+M8o90ZJsMOlIsjHuVouoki+keDllUgteDb6OEPJ7aWzmh0lhsdKmR3pJpeZHfJ1OhfLRUjZHq56TqQe/FbycbekZqdMcMMCZfJ1LjM7XC6CSHUY7Pg456OxFKzZKdNtxWCHfJ3OxTw7VgY7RKrj1qrna9ascfsFn3nmmQo3hpRne1EWQsgzGytas2NksEM1i87FchGlNxK3tElE5IJbwc7q1avtfr9w4QKuX7+OunXrAgCuXLmCWrVqoX79+gx2VMa2m8piFXKNTpGSo7HKZXZ4lSffJt9EuFgIlAXKROrh1tl48uRJ+WfZsmW47bbbcOLECVy6dAmXLl3CiRMn0LVrV/zf//1fZbeXPKSzKUC2rS+wKNmNxZodqmFcdWPJmR0WKBOphse3HgsWLMDatWvRtm1beVvbtm2xevVqzJ8/X9HGkfdsu6lsg53KGI0l/86h5+TjXAU78jw7XAiUSDU8DnYyMzNRWFhYbrvFYsH58+cVaRQpxzZzY7vSuUXBVHu5YIfdWOTjXAY7zOwQqY7H30qxsbF4/PHHcejQIYiSO5hDhw5h4sSJiIuLU7yB5B3bC26RzSzKRZUwqWDp78zskG9zK9jhaCwi1fA42HnrrbfQsGFD3HHHHfDz84PJZEL37t3RoEEDvPnmm5XRRvKCVquBdM21VFbNDguUqYZxthCo7SSDDHaI1MOt0VgSIQSuX7+ODz74AOfOncOJEycghED79u3Rpk2bymojeUmv1aLAYi1Ts6NkZodDz6lm0TuZVLCIwQ6RKnkc7LRu3RrHjx9H69at0bp168pqFylIp9UAlrKZHWvpY14y6dmNRTWL1sk8O7aZHgY7ROrhUX+DVqtF69atcfHixcpqD1UCR3eh0jw7SmR2tFqNXcDDYId8nTR/lbOZyYv3YbBDpBYeF1esWLECM2fOxLFjxyqjPVQJpCGwFgcFykpNfGYb4PjpWbNDvk06bcoGO7a/azkai0g1POrGAoCHH34Y169fR+fOnWE0GuHv72/3+KVLlxRrHCnDYWZHwZodoLgoOSdf+n9mdsi3OcvsWJjZIVIlj4OdV155pRKaQZVJujAX2c6zY1FuUkGgTGaHwQ75ODmzI1xkdhjsEKmGx8HO2LFjK6MdVIkczQmieGZHbxvssBuLfJt0AyFE8XBzbZlzjFkdInXxONixlZ+fX2425cDAQK8aRMqTF/90OM+OUjU7LFCmmsN2sk6LENDCfmFQZnWI1MXjb7pr165h8uTJqF+/PmrXro3g4GC7H1KfW5HZMdkVKDPYId9me49gN6WDhUtFEKmRx8HOc889hz179uCNN96AyWTCm2++icWLFyMyMhJvv/12ZbSRvFRaoFw6GkvO7ChUs+NvG+wY2Y1Fvk1vE+3YBTuC3VhEauTxt9Knn36KN954Aw899BD0ej3+9re/Yf78+XjhhRewbdu2CjckISEBGo0G8fHxDh+fOHEiNBpNuQJps9mMKVOmICwsDAEBARg2bBjOnj1b4Xb4Ip2DAuXKGI0FABoNYNQx2CHfZpvZKXIwWSe7sYjUxeNvpUuXLqF58+YAiutzpKHmvXr1wtdff12hRhw8eBAbNmxAdHS0w8c//vhjfPfdd4iMjCz3WHx8PLZv347ExETs27cPeXl5GDp0KCwWS4Xa4ov0DrqxlJxBGSit0/HT66BhCp98nG1mx2p3XkmP8xwgUhOPg50WLVrgjz/+AAB06NAB//nPfwAUZ3zq1q3rcQPy8vIwZswYbNy40WHNz7lz5zB58mRs27YNBoPB7rGcnBxs2rQJK1euRFxcHLp06YKtW7ciIyMDSUlJHrfFV+luxTw7JXU6HIlFNYHtaWN/XjGzQ6RGHn8zjRs3Dj/88AMAYM6cOXLtzrRp0zBz5kyPGzBp0iQMGTIEcXFx5R6zWq145JFHMHPmTHTs2LHc42lpaSgsLMTAgQPlbZGRkYiKikJqaqrHbfFVpZkdm5odS+WMxuJILKoJNBqNw5XPrczsEKmSx0PPp02bJv9/v3798NNPP+HQoUNo2bIlOnfu7NFrJSYm4vDhwzh48KDDx1988UXo9Xo888wzDh/PysqC0WgslxEKDw9HVlaW0/c1m80wm83y77m5uR61u7q5JZkdqRuLwQ7VEDqNBhYIhwXKXCqCSF08DnauX7+OWrVqyb83adIETZo08fiNz5w5g6lTp2LXrl3w8/Mr93haWhpeffVVHD582OMaECGEy+ckJCRg8eLFHre5utLrHNXsSJkdZYeel10BnchX6bQawOK4Fk6pmcmJSBkefzPVrVsXPXv2xNy5c/Hf//4X165dq9Abp6WlITs7GzExMdDr9dDr9UhJScGaNWug1+uRnJyM7OxsNGnSRH781KlTmD59Opo1awYAiIiIQEFBAS5fvmz32tnZ2QgPD3f63nPmzEFOTo78c+bMmQp9huriVo7GYmaHagpH81dJBcqcZ4dIXTzO7KSkpCAlJQXJycl47bXXcOPGDXTt2hV9+/ZFnz59MHjwYLdeJzY2FhkZGXbbxo0bh3bt2mHWrFlo0KABBg0aZPf4oEGD8Mgjj2DcuHEAgJiYGBgMBuzevRsjRowAAGRmZuLYsWNYsWKF0/c2mUwwmUyefOxqzeVoLIXn2fFnsEM1hOPuYWVHORKRMjwOdnr06IEePXpg9uzZsFgsOHjwINavX4+VK1fipZdecnvId506dRAVFWW3LSAgAKGhofL20NBQu8cNBgMiIiLQtm1bAEBQUBAmTJiA6dOnIzQ0FCEhIZgxYwY6derksOC5pnJ4UbYom9kJMBb/KdUyMtihmsFVgTKDHSJ1qdDaWD/99BOSk5PlDE9hYSHuvfde9OnTR+n23dTq1auh1+sxYsQI5OfnIzY2Flu2bIFOxy9diUFXfjRWaTeWMjU2/dvXx9DoBvjH7Z7XbxFVR/JNhIWZHSK18zjYiYiIQGFhIfr374++ffti7ty56NSpkyKNSU5Odvm4NL+PLT8/P6xduxZr165VpA2+SK7ZcVCgrFQhZVhtE14b3VWR1yKqDqS6HLvMjlC28J+IlOHxbX1ERATy8vJw+vRpnD59GmfPnkVeXl5ltI0U4qhmh3egRN5x1T3M84pIXTwOdtLT03H+/HnMmzcPRUVFWLBgAerVq4fu3btj9uzZldFG8pKji7JF4dFYRDWNo9FYcmaHo7GIVKVCNTt169bFsGHD0KtXL9x111345JNP8O677+LQoUNYvny50m0kL8mrnlvK1+woNYMyUU3jOGPKzA6RGnkc7Gzfvh3JyclITk7G8ePHERoair/97W9YvXo1+vXrVxltJC8xs0OkPK3DKR0Y7BCpkcfBzsSJE9G7d288/vjj6Nu3b7nh46Q+Du9AWVtA5BWpq4rBDpH6eRzsZGdnV0Y7qBK5HI3FizJRhcg1O4LBDpHaVahg47fffsP8+fMxatQoOfjZuXMnjh8/rmjjSBmO1sbiaCwi75QWKJfWwsnBDguUiVTF42AnJSUFnTp1wnfffYePPvpIHnZ+9OhRPP/884o3kLznaPIzpefZIappSoOd0m0WzrNDpEoeBzuzZ8/G0qVLsXv3bhiNRnl7v379sH//fkUbR8rQO7gD5WgsIu+4zOww2CFSFY+/6TIyMjB8+PBy2+vVq4eLFy8q0ihSFkdjESnPYWaHwQ6RKnkc7NStWxeZmZnlth85cgQNGzZUpFGkLM4HQqQ8eTQWC5SJVM/jYGf06NGYNWsWsrKyoNFoYLVa8e2332LGjBl49NFHK6ON5CVHo7GkCQaZ2SGqGL2DBXYZ7BCpk8fBzrJly9CkSRM0bNgQeXl56NChA3r37o2ePXti3rx5ldFG8pLB4WgsqUCZNTtEFaHVuChQ5mgsIlXxeJ4dg8GAbdu2YcmSJThy5AisViu6dOmC1q1bV0b7SAGs2SFSnqPCf4uFoxyJ1KhCa2MBQMuWLdGyZUv5948++giLFi3C0aNHFWkYKcf1aCxelIkqQuti6LmWmR0iVfGoD2Pjxo34+9//jtGjR+O7774DAOzZswddunTBww8/jB49elRKI8k7cs2Oo3l2GOwQVYjDzA7PKyJVcjvYefnllzFp0iScPHkSn3zyCfr3748XXngBI0aMwP3334/Tp0/jX//6V2W2lSpI76AbSypQZmaHqGJcLQSq5XlFpCpud2Nt2rQJ69evx/jx45GcnIz+/ftjz549+N///oe6detWYhPJW65rdligTFQRjm4imNkhUie3v+lOnTqFuLg4AEDfvn1hMBiwbNkyBjrVgKMhsnLNDgspiSpEGnFldTDPDjM7ROridrBz48YN+Pn5yb8bjUbUq1evUhpFynK5NhYvykQVonXUPcyFQIlUyaPRWG+++SZq164NACgqKsKWLVsQFhZmt88zzzyjXOtIEWVnUBZCcDQWkZek88pqE+xIWR7eRBCpi9vBTpMmTbBx40b594iICLzzzjt2+2g0GgY7KlR2BmWbazMvykQV5Cqzw24sInVxO9j5448/KrEZVJnKZnaKbGp3mNkhqhiHmR12DxOpEofi1ABlR2PZDpXlaCyiipEmDmRmh0j9+E1XA5Sd/Mz24szMDlHFyOeVYGaHSO0Y7NQA5TI7FtvMDi/KRBWhc9CNxeUiiNSJwU4NIK1sLnVfFZZkeLQaptuJKsrRZJ1FzOwQqRKDnRpAX2aeHc6eTOQ9R5kdK6d0IFKlCn3b/fbbb5g/fz5GjRqF7OxsAMDOnTtx/PhxRRtHytCVHY1l4QWZyFuuMjs63kgQqYrHZ2RKSgo6deqE7777Dh999BHy8vIAAEePHsXzzz+veAPJe9JyEWVHYzHVTlRxjpaLKM3sVEmTiMgJj0/J2bNnY+nSpdi9ezeMRqO8vV+/fti/f7+ijSNllC5YaD8ai+tiEVWcdP7YLsPCzA6ROnl8RmZkZGD48OHltterVw8XL16scEMSEhKg0WgQHx8PACgsLMSsWbPQqVMnBAQEIDIyEo8++ij+/PNPu+eZzWZMmTIFYWFhCAgIwLBhw3D27NkKt8MXSRdeS7maHQY7RBUlZXbshp4LZnaI1MjjU7Ju3brIzMwst/3IkSNo2LBhhRpx8OBBbNiwAdHR0fK269ev4/Dhw1iwYAEOHz6Mjz76CL/88guGDRtm99z4+Hhs374diYmJ2LdvH/Ly8jB06FBYLJYKtcUX6cvUFkgZHtbsEFVc2Vo4wLYejtEOkZp4fEaOHj0as2bNQlZWFjQaDaxWK7799lvMmDEDjz76qMcNyMvLw5gxY7Bx40YEBwfL24OCgrB7926MGDECbdu2xZ133om1a9ciLS0Np0+fBgDk5ORg06ZNWLlyJeLi4tClSxds3boVGRkZSEpK8rgtvqrsRZmjsYi85yjYkbI8XPWcSF08/rZbtmwZmjRpgoYNGyIvLw8dOnRA79690bNnT8yfP9/jBkyaNAlDhgxBXFzcTffNycmBRqNB3bp1AQBpaWkoLCzEwIED5X0iIyMRFRWF1NRUp69jNpuRm5tr9+PLnNbsMLNDVGFl15yz/X+eW0Tq4vZCoBKDwYBt27ZhyZIlOHLkCKxWK7p06YLWrVt7/OaJiYk4fPgwDh48eNN9b9y4gdmzZ2P06NEIDAwEAGRlZcFoNNplhAAgPDwcWVlZTl8rISEBixcv9ri91ZU8H4goHi3Cmh0i72kZ7BBVGx4HOykpKejTpw9atmyJli1bVviNz5w5g6lTp2LXrl3w8/NzuW9hYSH+8Y9/wGq14o033rjpawshoHGRRp4zZw6effZZ+ffc3Fw0btzY/cZXM7bdVRYhOM8OkQLkAmWHwU6VNImInPD4lBwwYACaNGmC2bNn49ixYxV+47S0NGRnZyMmJgZ6vR56vR4pKSlYs2YN9Hq9XGBcWFiIESNG4OTJk9i9e7ec1QGAiIgIFBQU4PLly3avnZ2djfDwcKfvbTKZEBgYaPfjy2yHmFtsMjsMdogqTq7ZEY6CHUY7RGri8Rn5559/4rnnnsM333yD6OhoREdHY8WKFR4P946NjUVGRgbS09Pln27dumHMmDFIT0+HTqeTA51ff/0VSUlJCA0NtXuNmJgYGAwG7N69W96WmZmJY8eOoWfPnp5+NJ9l211VZBVy7Y6e8+wQVZjDAmUrC5SJ1MjjbqywsDBMnjwZkydPxsmTJ/Huu+/i7bffxty5c9G7d2/s2bPHrdepU6cOoqKi7LYFBAQgNDQUUVFRKCoqwkMPPYTDhw/js88+g8ViketwQkJCYDQaERQUhAkTJmD69OkIDQ1FSEgIZsyYgU6dOrlV8FxT2GZwLBbBu08iBbgcjcWsKZGqeBzs2GrevDlmz56Nzp07Y8GCBUhJSVGqXTh79ix27NgBALjtttvsHtu7dy/69u0LAFi9ejX0ej1GjBiB/Px8xMbGYsuWLdDpdIq1pbqzz+xYuTIzkQIcrY3FLmIidapwsPPtt99i27Zt+OCDD3Djxg0MGzYML7zwgleNSU5Olv+/WbNmEDZ94c74+flh7dq1WLt2rVfv7cs0Gg10Wo1cryMVKDPYIao46fyxMtghUj2Pg525c+fi//2//4c///wTcXFxeOWVV3D//fejVq1aldE+UogU7LBmh0gZWgfLRTDYIVInj4Od5ORkzJgxAyNHjkRYWFhltIkqgV6rQQHKjsZizQ5RRUk3C44KlJk1JVIXj4MdVzMTk3pJd5qFFtbsEClB62ienZIsj5ajsYhUxa1gZ8eOHRg8eDAMBoNcNOxM2YU6SR1sp7Znqp3Ie9JknQ4zO+wiJlIVt4Kd+++/H1lZWahfvz7uv/9+p/tpNBquNq5SUpdVUUndDsDMDpE3pF5gR8EOMztE6uJWsGMtKWgt+/9UfdhldizF/4bM7BBVnMvMDs8tIlXxuEL17bffhtlsLre9oKAAb7/9tiKNIuXZzgnCzA6R96T1rzgai0j9PA52xo0bh5ycnHLbr169inHjxinSKFJe6cgRK0djESlA7hq2MNghUjuPv+2crSh+9uxZBAUFKdIoUp6c2bEws0OkBGn9K6soPxqLwQ6Rurg99LxLly7QaDTQaDSIjY2FXl/6VIvFgpMnT+Luu++ulEaS9xyOxuKIEaIKK7tchBAc6UikVm4HO9IorPT0dAwaNAi1a9eWHzMajWjWrBkefPBBxRtIyuBoLCJl6cosF2FTp8xVz4lUxu1g5/nnnwdQvGbVyJEj4efnV2mNIuXZZ3Y4GovIW1KBsnTzUGQzUlXLc4tIVTyeQXns2LGV0Q6qZByNRaQsKVsqZ3ZsZuXguUWkLh4HOxaLBatXr8Z//vMfnD59GgUFBXaPX7p0SbHGkXIMtqOxpFXPdRyNRVRRUleVo8wOs6ZE6uLxt93ixYuxatUqjBgxAjk5OXj22WfxwAMPQKvVYtGiRZXQRFICMztEypIK/KURWLaZHQY7ROricbCzbds2bNy4ETNmzIBer8eoUaPw5ptvYuHChThw4EBltJEUYDvbaxFrdoi8Jg89L7l5sJ1ckAXKROricbCTlZWFTp06AQBq164tTzA4dOhQfP7558q2jhRTuuq54JT2RAooO/RcuonQaFigTKQ2Hgc7jRo1QmZmJgCgVatW2LVrFwDg4MGDMJlMyraOFFM6Gssqz/jKGZSJKs42M2q1Crkbi1kdIvXx+Ntu+PDh+OqrrwAAU6dOxYIFC9C6dWs8+uijGD9+vOINJGXY3oUys0PkPdtgp4jdw0Sq5vForOXLl8v//9BDD6FRo0ZITU1Fq1atMGzYMEUbR8opXRurtECZF2WiirPL7AibzA7PKyLV8TjYKevOO+/EnXfeqURbqBLZLlooZ3a4XARRhemZ2SGqNtwKdnbs2OH2CzK7o062MyjzokzkPa1NbY7FKuQFQXleEamPW8GOtC7WzWg0GlgsFm/aQ5WENTtEyrI9fyycv4pI1dwKdqy2s2VRtWQ3GsvK0VhE3tKWCXakmwgtR2MRqQ6/7WoIZnaIlGe/wC7PKyK18rhAecmSJS4fX7hwYYUbQ5XHrmbHwtoCIiVotRrAKmARNpkdnldEquNxsLN9+3a73wsLC3Hy5Eno9Xq0bNmSwY5KyaOxeAdKpBhpAkGLzShH3kQQqY/Hwc6RI0fKbcvNzcVjjz2G4cOHK9IoUp5BV340Flc9J/KOnDEVDHaI1EyRb7vAwEAsWbIECxYsUOLlqBLINTsWjhohUorWpvBfDnZYoEykOord2l+5ckVeFJTUx/HaWLwoE3mj9LwqXfWc5xWR+ngc7KxZs8bu59VXX8Xs2bMxcuRI3H333RVuSEJCAjQaDeLj4+VtQggsWrQIkZGR8Pf3R9++fXH8+HG755nNZkyZMgVhYWEICAjAsGHDcPbs2Qq3w1dJNTuFrNkhUoxWHuVo5TIsRCrmcc3O6tWr7X7XarWoV68exo4dizlz5lSoEQcPHsSGDRsQHR1tt33FihVYtWoVtmzZgjZt2mDp0qUYMGAAfv75Z9SpUwcAEB8fj08//RSJiYkIDQ3F9OnTMXToUKSlpUGn01WoPb5IXhvLwhmUiZQi3TBYrcUrn9tuIyL18DjYOXnypKINyMvLw5gxY7Bx40YsXbpU3i6EwCuvvIJ58+bhgQceAAD8+9//Rnh4ON59911MnDgROTk52LRpE9555x3ExcUBALZu3YrGjRsjKSkJgwYNUrSt1ZnDeXa4NhaRV6QJBDn0nEjdqnw4zqRJkzBkyBA5WJGcPHkSWVlZGDhwoLzNZDKhT58+SE1NBQCkpaWhsLDQbp/IyEhERUXJ+zhiNpuRm5tr9+PrOIMykfLkjKlNgTIzO0Tq43Fm58aNG1i7di327t2L7OzscktJHD582O3XSkxMxOHDh3Hw4MFyj2VlZQEAwsPD7baHh4fj1KlT8j5GoxHBwcHl9pGe70hCQgIWL17sdjt9AWdQJlKePM+OTYEyl4sgUh+Pg53x48dj9+7deOihh3DHHXdAU8ET+8yZM5g6dSp27doFPz8/p/uVfX0hxE3f82b7zJkzB88++6z8e25uLho3buxmy6sn+1XPWUhJpASdTYEyu4eJ1MvjYOfzzz/HF198gbvuusurN05LS0N2djZiYmLkbRaLBV9//TVee+01/PzzzwCKszcNGjSQ98nOzpazPRERESgoKMDly5ftsjvZ2dno2bOn0/c2mUwwmUxetb+64QzKRMrT2RQocyFQIvXyuGijYcOG8kgob8TGxiIjIwPp6enyT7du3TBmzBikp6ejRYsWiIiIwO7du+XnFBQUICUlRQ5kYmJiYDAY7PbJzMzEsWPHXAY7NZH92lgcjUWkBJ2Doee8iSBSH48zOytXrsSsWbOwfv16NG3atMJvXKdOHURFRdltCwgIQGhoqLw9Pj4eL7zwAlq3bo3WrVvjhRdeQK1atTB69GgAQFBQECZMmIDp06cjNDQUISEhmDFjBjp16lSu4Lmmc1yzwwJlIm/ImR0h5KHnvIkgUh+Pg51u3brhxo0baNGiBWrVqgWDwWD3+KVLlxRr3HPPPYf8/Hw8/fTTuHz5Mrp3745du3bZZZZWr14NvV6PESNGID8/H7GxsdiyZQvn2CnDdtSIXLPD2gIirzhahoXBDpH6eBzsjBo1CufOncMLL7yA8PDwChcoO5KcnGz3u0ajwaJFi7Bo0SKnz/Hz88PatWuxdu1axdrhi2wvyqzZIVKGNBrLKgSsXC6CSLU8DnZSU1Oxf/9+dO7cuTLaQ5VEb9ONxTtQImXYdg+XrjnH7mEitfH4rGzXrh3y8/Mroy1UiaT6nEJL6bxIBl6Uibyisyn8lzM7vIcgUh2Pv+2WL1+O6dOnIzk5GRcvXqxxMxFXV1J9zo1CS7ltRFQxOgfzV3G5CCL18bgbS1rZPDY21m67NJGfxWJx9DSqYlI31o1Ca7ltRFQxtsEOa+GI1MvjYGfv3r2V0Q6qZNJF2VxkKbeNiCqmdLmI0mCH5xWR+ngc7PTp06cy2kGVTKrZMReVZnZ0nOmVyCtyZkcw2CFSM4+Dna+//trl4717965wY6jyyJmdkm4srYa1BUTectSNxZsIIvXxONjp27dvuW22c+2wZked9GW6sTh7MpH37IIdwaHnRGrl8Vl5+fJlu5/s7Gzs3LkTt99+O3bt2lUZbSQFlE5rb/87EVWc3dBzuRurKltERI54nNkJCgoqt23AgAEwmUyYNm0a0tLSFGkYKUtfZpg5R4wQec/R0HNmdojUR7Gzsl69evj555+VejlSWNnghnPsEHlPHo1lV6BclS0iIkc8zuwcPXrU7nchBDIzM7F8+XIuIaFiZe82mdkh8p68wK7FNthhtEOkNh4HO7fddhs0Gg1ESTGe5M4778Rbb72lWMNIWeUyOwx2iLymtc3sCI7GIlIrj4OdkydP2v2u1WpRr149+Pn5KdYoUl7Z4IajsYi8p7cdjVWyEGjZ+jgiqnoeBztNmzatjHZQJWNmh0h5WgdDz7XM7BCpjtu393v27EGHDh0cLvaZk5ODjh074ptvvlG0caQcfZmqSd59EnlPz7WxiKoFt4OdV155BY8//jgCAwPLPRYUFISJEydi1apVijaOlFO+G4sXZCJvaR0EO5yZnEh93A52fvjhB3nFc0cGDhzIOXZUrHw3Fmt2iLwlFSMX2S0XUZUtIiJH3P7GO3/+PAwGg9PH9Xo9Lly4oEijSHnM7BApTy/PTG4T7HCiHSLVcfusbNiwITIyMpw+fvToUTRo0ECRRpHyWKBMpDypy6rIdgZlFigTqY7bwc4999yDhQsX4saNG+Uey8/Px/PPP4+hQ4cq2jhSDjM7RMqTMztWAatggTKRWrk99Hz+/Pn46KOP0KZNG0yePBlt27aFRqPBiRMn8Prrr8NisWDevHmV2VbygkajgU6rsZnllRdkIm85yuywQJlIfdwOdsLDw5GamoqnnnoKc+bMkWdQ1mg0GDRoEN544w2Eh4dXWkPJe7bBDoeeE3nPLrPDoedEquXRpIJNmzbFF198gcuXL+N///sfhBBo3bo1goODK6t9pCC9VoOCkv/naCwi72kdLATKzA6R+ng8gzIABAcH4/bbb1e6LVTJbLuuePdJ5D29tvzQc55bROrD2/saxPYizJodIu/pbLqxuFwEkXox2KlBbLuuePdJ5D3pnLItUOa5RaQ+DHZqEGZ2iJQlzR9oW6DMc4tIfRjs1CCs2SFSlqPMDoMdIvVhsFODGGyGm5ddBZ2IPCdndgQzO0RqVqXfeOvWrUN0dDQCAwMRGBiIHj164Msvv5Qfz8vLw+TJk9GoUSP4+/ujffv2WLdund1rmM1mTJkyBWFhYQgICMCwYcNw9uzZW/1RqgVmdoiUJWd2LAJFVmvJNp5bRGpTpcFOo0aNsHz5chw6dAiHDh1C//79cd999+H48eMAgGnTpmHnzp3YunUrTpw4gWnTpmHKlCn45JNP5NeIj4/H9u3bkZiYiH379iEvLw9Dhw6FxWKpqo+lWnqbAmVekIm8p7OZZ6ckscNzi0iFqjTYuffee3HPPfegTZs2aNOmDZYtW4batWvjwIEDAID9+/dj7Nix6Nu3L5o1a4YnnngCnTt3xqFDhwAAOTk52LRpE1auXIm4uDh06dIFW7duRUZGBpKSkqryo6kSMztEypLOKYuVmR0iNVNN4YbFYkFiYiKuXbuGHj16AAB69eqFHTt24Ny5cxBCYO/evfjll18waNAgAEBaWhoKCwsxcOBA+XUiIyMRFRWF1NRUp+9lNpuRm5tr91MT2C4RwRmUibxnG+yUxDpc9ZxIhSo0g7KSMjIy0KNHD9y4cQO1a9fG9u3b0aFDBwDAmjVr8Pjjj6NRo0bQ6/XQarV488030atXLwBAVlYWjEZjueUqwsPDkZWV5fQ9ExISsHjx4sr7UCpll9nh2lhEXpMKlJnZIVK3Kr+9b9u2LdLT03HgwAE89dRTGDt2LH788UcAxcHOgQMHsGPHDqSlpWHlypV4+umnb9pFJYSAxsXd1Zw5c5CTkyP/nDlzRtHPpFacZ4dIWVKG1GIVsEiZHZ5bRKpT5Zkdo9GIVq1aAQC6deuGgwcP4tVXX8Urr7yCuXPnYvv27RgyZAgAIDo6Gunp6Xj55ZcRFxeHiIgIFBQU4PLly3bZnezsbPTs2dPpe5pMJphMpsr9YCrEmh0iZckFylYBCzM7RKpV5ZmdsoQQMJvNKCwsRGFhIbRlakt0Oh2sJReVmJgYGAwG7N69W348MzMTx44dcxns1FQcjUWkLLlmx2bVc55bROpTpZmduXPnYvDgwWjcuDGuXr2KxMREJCcnY+fOnQgMDESfPn0wc+ZM+Pv7o2nTpkhJScHbb7+NVatWAQCCgoIwYcIETJ8+HaGhoQgJCcGMGTPQqVMnxMXFVeVHUyVmdoiUZVugLAc7LFAmUp0qDXbOnz+PRx55BJmZmQgKCkJ0dDR27tyJAQMGAAASExMxZ84cjBkzBpcuXULTpk2xbNkyPPnkk/JrrF69Gnq9HiNGjEB+fj5iY2OxZcsW6HS6qvpYqmVfs6O6pB5RtWMX7AhmdojUqkqDnU2bNrl8PCIiAps3b3a5j5+fH9auXYu1a9cq2TSfxMwOkbIcDj3nuUWkOry9r0Hs59nhBZnIW3oHkwryRoJIfRjs1CC2XVecZ4fIe9qS+pwia+lyEVoGO0Sqw2CnBjHYdWPxn57IW9JNQ6E0yQ6Y2SFSI37j1SCs2SFSlpTZKSgqDXaY2SFSHwY7NQhrdoiUJd00FDCzQ6RqDHZqEK6NRaQs29FYEi3n2SFSHQY7NQhnUCZSlqPziJkdIvVhsFODsGaHSFmOgh3eSBCpD4OdGoQzKBMpq2yXlUYDaNiNRaQ6/MarQZjZIVJW2fOI5xWROjHYqUHsMzu8KBN5q+wwcxYnE6kTg50axG4GZQY7RF5jZoeoemCwU4Nwnh0iZZU9jzihIJE6MdipQTjPDpGyygY7zOwQqRODnRqEo7GIlKUrU6PDjCmROvEbrwbhaCwiZWm1GtjGOwx2iNSJwU4NwtFYRMqzze6UzfQQkTow2KlB9LrSf24Da3aIFGF746DjeUWkSgx2ahAda3aIFGd3XjGzQ6RK/MarQfSs2SFSnI7dw0Sqx2CnBuFFmUh5PK+I1I/BTg2i5wzKRIrjlA5E6sczswbhHSiR8mzXw9LxikqkSjw1axD7mh3+0xMpgZkdIvXjmVmD2A6L5RBZImVo7UZjVWFDiMgpBjs1CEdjESmP3cNE6sdgpwbhRZlIeTyviNSPwU4NYlunw8nPiJRht1wEgx0iVWKwU4NIF2Ktxr7OgIgqjjOTE6kfz8waRKrT4UgsIuXoWKBMpHpV+q23bt06REdHIzAwEIGBgejRowe+/PJLu31OnDiBYcOGISgoCHXq1MGdd96J06dPy4+bzWZMmTIFYWFhCAgIwLBhw3D27Nlb/VGqBemizFQ7kXI49JxI/ar0zGzUqBGWL1+OQ4cO4dChQ+jfvz/uu+8+HD9+HADw22+/oVevXmjXrh2Sk5Pxww8/YMGCBfDz85NfIz4+Htu3b0diYiL27duHvLw8DB06FBaLpao+lmoZSmY80/P2k0gxdkPPGesQqZK+Kt/83nvvtft92bJlWLduHQ4cOICOHTti3rx5uOeee7BixQp5nxYtWsj/n5OTg02bNuGdd95BXFwcAGDr1q1o3LgxkpKSMGjQoFvzQaqJIH8DAKBuLUMVt4TId3CyTiL1U82ZabFYkJiYiGvXrqFHjx6wWq34/PPP0aZNGwwaNAj169dH9+7d8fHHH8vPSUtLQ2FhIQYOHChvi4yMRFRUFFJTU6vgU6hbRJAf/vVIDF4b1bWqm0LkM2yXi2DhP5E6VXmwk5GRgdq1a8NkMuHJJ5/E9u3b0aFDB2RnZyMvLw/Lly/H3XffjV27dmH48OF44IEHkJKSAgDIysqC0WhEcHCw3WuGh4cjKyvL6XuazWbk5uba/dQUgzpGoHPjulXdDCKfYdstzMk6idSpSruxAKBt27ZIT0/HlStX8OGHH2Ls2LFISUlB3bp1AQD33Xcfpk2bBgC47bbbkJqaivXr16NPnz5OX1MIAY2LeWQSEhKwePFiRT8HEdVMdpkdzl9FpEpVntkxGo1o1aoVunXrhoSEBHTu3BmvvvoqwsLCoNfr0aFDB7v927dvL4/GioiIQEFBAS5fvmy3T3Z2NsLDw52+55w5c5CTkyP/nDlzRvkPRkQ1ApdhIVK/Kg92yhJCwGw2w2g04vbbb8fPP/9s9/gvv/yCpk2bAgBiYmJgMBiwe/du+fHMzEwcO3YMPXv2dPoeJpNJHu4u/RARVYTtVA6s2SFSpyrtxpo7dy4GDx6Mxo0b4+rVq0hMTERycjJ27twJAJg5cyZGjhyJ3r17o1+/fti5cyc+/fRTJCcnAwCCgoIwYcIETJ8+HaGhoQgJCcGMGTPQqVMneXQWEVFl0jGzQ6R6VRrsnD9/Ho888ggyMzMRFBSE6Oho7Ny5EwMGDAAADB8+HOvXr0dCQgKeeeYZtG3bFh9++CF69eolv8bq1auh1+sxYsQI5OfnIzY2Flu2bIFOp6uqj0VENQgXAiVSP40QQlR1I6pabm4ugoKCkJOTwy4tIvLI5HcP47OjmQCA8Xc1x8J7O9zkGUSkFHe/v1VXs0NEVJ3YFShzdnIiVWKwQ0TkBduiZA49J1InBjtERF7g0HMi9WOwQ0TkBQ49J1I/BjtERF7g0HMi9WOwQ0TkBZ2GQ8+J1I7BDhGRF3Rarc3/M9ghUiMGO0REXtDZXEV1HI1FpEoMdoiIvMDMDpH6MdghIvKCXWaHwQ6RKjHYISLyAjM7ROrHYIeIyAscjUWkfgx2iIi8YLseFoMdInVisENE5AXb9bA4GotInRjsEBF5gaueE6kfgx0iIi9w1XMi9WOwQ0TkBdtkDmt2iNSJwQ4RkRd0Og49J1I7BjtERF7QsUCZSPUY7BARecG2QFnHAmUiVWKwQ0TkBdsCZWZ2iNSJwQ4RkRfshp6zZodIlRjsEBF5wW7oOYMdIlVisENE5AVmdojUj8EOEZEXbCcSZGaHSJ0Y7BAReYGZHSL1Y7BDROQFHZeLIFI9BjtERF7QcSFQItVjsENE5AUd59khUj0GO0REXrALdlizQ6RKVRrsrFu3DtHR0QgMDERgYCB69OiBL7/80uG+EydOhEajwSuvvGK33Ww2Y8qUKQgLC0NAQACGDRuGs2fP3oLWExEx2CGqDqo02GnUqBGWL1+OQ4cO4dChQ+jfvz/uu+8+HD9+3G6/jz/+GN999x0iIyPLvUZ8fDy2b9+OxMRE7Nu3D3l5eRg6dCgsFsut+hhEVIPZDT1nNxaRKlVpsHPvvffinnvuQZs2bdCmTRssW7YMtWvXxoEDB+R9zp07h8mTJ2Pbtm0wGAx2z8/JycGmTZuwcuVKxMXFoUuXLti6dSsyMjKQlJR0qz8OEdVAehYoE6meamp2LBYLEhMTce3aNfTo0QMAYLVa8cgjj2DmzJno2LFjueekpaWhsLAQAwcOlLdFRkYiKioKqampt6ztRFRzsUCZSP30Vd2AjIwM9OjRAzdu3EDt2rWxfft2dOjQAQDw4osvQq/X45lnnnH43KysLBiNRgQHB9ttDw8PR1ZWltP3NJvNMJvN8u+5ubkKfBIiqolYs0OkflUe7LRt2xbp6em4cuUKPvzwQ4wdOxYpKSnIz8/Hq6++isOHD0Pj4d2SEMLlcxISErB48WJvm05ExGCHqBqo8m4so9GIVq1aoVu3bkhISEDnzp3x6quv4ptvvkF2djaaNGkCvV4PvV6PU6dOYfr06WjWrBkAICIiAgUFBbh8+bLda2ZnZyM8PNzpe86ZMwc5OTnyz5kzZyrzIxKRD2OwQ6R+VR7slCWEgNlsxiOPPIKjR48iPT1d/omMjMTMmTPx3//+FwAQExMDg8GA3bt3y8/PzMzEsWPH0LNnT6fvYTKZ5OHu0g8RUUXY1ukw2CFSpyrtxpo7dy4GDx6Mxo0b4+rVq0hMTERycjJ27tyJ0NBQhIaG2u1vMBgQERGBtm3bAgCCgoIwYcIETJ8+HaGhoQgJCcGMGTPQqVMnxMXFVcVHIqIahpkdIvWr0mDn/PnzeOSRR5CZmYmgoCBER0dj586dGDBggNuvsXr1auj1eowYMQL5+fmIjY3Fli1boNPpKrHlRETFOBqLSP00QghR1Y2oarm5uQgKCkJOTg67tIjII9m5N3DHC18BAE4m3OPxgAoiqjh3v7+rfDQWEVF1FlbbhLtahSI0wMRAh0ilGOwQEXlBq9Vg2z/vrOpmEJELqhuNRURERKQkBjtERETk0xjsEBERkU9jsENEREQ+jcEOERER+TQGO0REROTTGOwQERGRT2OwQ0RERD6NwQ4RERH5NAY7RERE5NMY7BAREZFPY7BDREREPo3BDhEREfk0BjtERETk0/RV3QA1EEIAAHJzc6u4JUREROQu6Xtb+h53hsEOgKtXrwIAGjduXMUtISIiIk9dvXoVQUFBTh/XiJuFQzWA1WrFn3/+iTp16kCj0VT4dXJzc9G4cWOcOXMGgYGBCraQyuKxvnV4rG8dHutbh8f61qnMYy2EwNWrVxEZGQmt1nllDjM7ALRaLRo1aqTY6wUGBvLkuUV4rG8dHutbh8f61uGxvnUq61i7yuhIWKBMREREPo3BDhEREfk0BjsKMplMeP7552Eymaq6KT6Px/rW4bG+dXisbx0e61tHDceaBcpERETk05jZISIiIp/GYIeIiIh8GoMdIiIi8mkMdoiIiMinMdhRyBtvvIHmzZvDz88PMTEx+Oabb6q6SdVeQkICbr/9dtSpUwf169fH/fffj59//tluHyEEFi1ahMjISPj7+6Nv3744fvx4FbXYdyQkJECj0SA+Pl7exmOtnHPnzuHhhx9GaGgoatWqhdtuuw1paWny4zzWyigqKsL8+fPRvHlz+Pv7o0WLFliyZAmsVqu8D491xX399de49957ERkZCY1Gg48//tjucXeOrdlsxpQpUxAWFoaAgAAMGzYMZ8+eVb6xgryWmJgoDAaD2Lhxo/jxxx/F1KlTRUBAgDh16lRVN61aGzRokNi8ebM4duyYSE9PF0OGDBFNmjQReXl58j7Lly8XderUER9++KHIyMgQI0eOFA0aNBC5ublV2PLq7fvvvxfNmjUT0dHRYurUqfJ2HmtlXLp0STRt2lQ89thj4rvvvhMnT54USUlJ4n//+5+8D4+1MpYuXSpCQ0PFZ599Jk6ePCnef/99Ubt2bfHKK6/I+/BYV9wXX3wh5s2bJz788EMBQGzfvt3ucXeO7ZNPPikaNmwodu/eLQ4fPiz69esnOnfuLIqKihRtK4MdBdxxxx3iySeftNvWrl07MXv27CpqkW/Kzs4WAERKSooQQgir1SoiIiLE8uXL5X1u3LghgoKCxPr166uqmdXa1atXRevWrcXu3btFnz595GCHx1o5s2bNEr169XL6OI+1coYMGSLGjx9vt+2BBx4QDz/8sBCCx1pJZYMdd47tlStXhMFgEImJifI+586dE1qtVuzcuVPR9rEby0sFBQVIS0vDwIED7bYPHDgQqampVdQq35STkwMACAkJAQCcPHkSWVlZdsfeZDKhT58+PPYVNGnSJAwZMgRxcXF223mslbNjxw5069YNf//731G/fn106dIFGzdulB/nsVZOr1698NVXX+GXX34BAPzwww/Yt28f7rnnHgA81pXJnWOblpaGwsJCu30iIyMRFRWl+PHnQqBe+uuvv2CxWBAeHm63PTw8HFlZWVXUKt8jhMCzzz6LXr16ISoqCgDk4+vo2J86deqWt7G6S0xMxOHDh3Hw4MFyj/FYK+f333/HunXr8Oyzz2Lu3Ln4/vvv8cwzz8BkMuHRRx/lsVbQrFmzkJOTg3bt2kGn08FisWDZsmUYNWoUAP5dVyZ3jm1WVhaMRiOCg4PL7aP09yeDHYVoNBq734UQ5bZRxU2ePBlHjx7Fvn37yj3GY++9M2fOYOrUqdi1axf8/Pyc7sdj7T2r1Ypu3brhhRdeAAB06dIFx48fx7p16/Doo4/K+/FYe++9997D1q1b8e6776Jjx45IT09HfHw8IiMjMXbsWHk/HuvKU5FjWxnHn91YXgoLC4NOpysXhWZnZ5eLaKlipkyZgh07dmDv3r1o1KiRvD0iIgIAeOwVkJaWhuzsbMTExECv10Ov1yMlJQVr1qyBXq+XjyePtfcaNGiADh062G1r3749Tp8+DYB/10qaOXMmZs+ejX/84x/o1KkTHnnkEUybNg0JCQkAeKwrkzvHNiIiAgUFBbh8+bLTfZTCYMdLRqMRMTEx2L17t9323bt3o2fPnlXUKt8ghMDkyZPx0UcfYc+ePWjevLnd482bN0dERITdsS8oKEBKSgqPvYdiY2ORkZGB9PR0+adbt24YM2YM0tPT0aJFCx5rhdx1113lplD45Zdf0LRpUwD8u1bS9evXodXaf83pdDp56DmPdeVx59jGxMTAYDDY7ZOZmYljx44pf/wVLXeuoaSh55s2bRI//vijiI+PFwEBAeKPP/6o6qZVa0899ZQICgoSycnJIjMzU/65fv26vM/y5ctFUFCQ+Oijj0RGRoYYNWoUh40qxHY0lhA81kr5/vvvhV6vF8uWLRO//vqr2LZtm6hVq5bYunWrvA+PtTLGjh0rGjZsKA89/+ijj0RYWJh47rnn5H14rCvu6tWr4siRI+LIkSMCgFi1apU4cuSIPO2KO8f2ySefFI0aNRJJSUni8OHDon///hx6rmavv/66aNq0qTAajaJr167y8GiqOAAOfzZv3izvY7VaxfPPPy8iIiKEyWQSvXv3FhkZGVXXaB9SNtjhsVbOp59+KqKiooTJZBLt2rUTGzZssHucx1oZubm5YurUqaJJkybCz89PtGjRQsybN0+YzWZ5Hx7ritu7d6/Da/TYsWOFEO4d2/z8fDF58mQREhIi/P39xdChQ8Xp06cVb6tGCCGUzRURERERqQdrdoiIiMinMdghIiIin8Zgh4iIiHwagx0iIiLyaQx2iIiIyKcx2CEiIiKfxmCHiIiIfBqDHSKqtv744w9oNBqkp6dX2ns89thjuP/++yvt9Ymo8jHYIaIq89hjj0Gj0ZT7ufvuu916fuPGjZGZmYmoqKhKbikRVWf6qm4AEdVsd999NzZv3my3zWQyufVcnU4nr65MROQMMztEVKVMJhMiIiLsfoKDgwEAGo0G69atw+DBg+Hv74/mzZvj/fffl59bthvr8uXLGDNmDOrVqwd/f3+0bt3aLpDKyMhA//794e/vj9DQUDzxxBPIy8uTH7dYLHj22WdRt25dhIaG4rnnnkPZFXWEEFixYgVatGgBf39/dO7cGR988EElHiEi8haDHSJStQULFuDBBx/EDz/8gIcffhijRo3CiRMnnO77448/4ssvv8SJEyewbt06hIWFAQCuX7+Ou+++G8HBwTh48CDef/99JCUlYfLkyfLzV65cibfeegubNm3Cvn37cOnSJWzfvt3uPebPn4/Nmzdj3bp1OH78OKZNm4aHH34YKSkplXcQiMg7ii8tSkTkprFjxwqdTicCAgLsfpYsWSKEEAKAePLJJ+2e0717d/HUU08JIYQ4efKkACCOHDkihBDi3nvvFePGjXP4Xhs2bBDBwcEiLy9P3vb5558LrVYrsrKyhBBCNGjQQCxfvlx+vLCwUDRq1Ejcd999Qggh8vLyhJ+fn0hNTbV77QkTJohRo0ZV/EAQUaVizQ4RVal+/fph3bp1dttCQkLk/+/Ro4fdYz169HA6+uqpp57Cgw8+iMOHD2PgwIG4//770bNnTwDAiRMn0LlzZwQEBMj733XXXbBarfj555/h5+eHzMxMu/fT6/Xo1q2b3JX1448/4saNGxgwYIDd+xYUFKBLly6ef3giuiUY7BBRlQoICECrVq08eo5Go3G4ffDgwTh16hQ+//xzJCUlITY2FpMmTcLLL78MIYTT5znbXpbVagUAfP7552jYsKHdY+4WVRPRrceaHSJStQMHDpT7vV27dk73r1evHh577DFs3boVr7zyCjZs2AAA6NChA9LT03Ht2jV532+//RZarRZt2rRBUFAQGjRoYPd+RUVFSEtLk3/v0KEDTCYTTp8+jVatWtn9NG7cWKmPTEQKY2aHiKqU2WxGVlaW3Ta9Xi8XFr///vvo1q0bevXqhW3btuH777/Hpk2bHL7WwoULERMTg44dO8JsNuOzzz5D+/btAQBjxozB888/j7Fjx2LRokW4cOECpkyZgkceeQTh4eEAgKlTp2L58uVo3bo12rdvj1WrVuHKlSvy69epUwczZszAtGnTYLVa0atXL+Tm5iI1NRW1a9fG2LFjK+EIEZG3GOwQUZXauXMnGjRoYLetbdu2+OmnnwAAixcvRmJiIp5++mlERERg27Zt6NChg8PXMhqNmDNnDv744w/4+/vjb3/7GxITEwEAtWrVwn//+19MnToVt99+O2rVqoUHH3wQq1atkp8/ffp0ZGZm4rHHHoNWq8X48eMxfPhw5OTkyPv83//9H+rXr4+EhAT8/vvvqFu3Lrp27Yq5c+cqfWiISCEaIcpMIkFEpBIajQbbt2/ncg1E5BXW7BAREZFPY7BDREREPo01O0SkWuxlJyIlMLNDREREPo3BDhEREfk0BjtERETk0xjsEBERkU9jsENEREQ+jcEOERER+TQGO0REROTTGOwQERGRT2OwQ0RERD7t/wOEvAJPYReFrgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the cumulative rewards\n",
    "plt.plot(range(1, episodes + 1), cumilative_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Cumulative Rewards Over Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b8dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cummulative reward:  [495.58]\n"
     ]
    }
   ],
   "source": [
    "mean = sum(cumilative_rewards) / len(cumilative_rewards)\n",
    "print(\"Average cummulative reward: \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c27bca",
   "metadata": {},
   "source": [
    "From the results in the cummulative graph, we could see that for every episode, the rewards are consistent with an average value of around <code> 490-500 </code>. This indicated that the RL agent has successfully learned the PPO to effectively balance the pole on the cart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c8b38",
   "metadata": {},
   "source": [
    "<h1> Task 3: Render an episode played by RL agent </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92e9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3a3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\Shun Jie\\Documents\\Github\\pole-cart-balancer-rl\\logs\\videos\\ppo-agent-CartPole-v1-step-0-to-step-1000.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Shun Jie\\Documents\\Github\\pole-cart-balancer-rl\\logs\\videos\\ppo-agent-CartPole-v1-step-0-to-step-1000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Shun Jie\\Documents\\Github\\pole-cart-balancer-rl\\logs\\videos\\ppo-agent-CartPole-v1-step-0-to-step-1000.mp4\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "vec_env = DummyVecEnv([lambda: gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")])\n",
    "obs = vec_env.reset()\n",
    "\n",
    "#Record the environment at the first step\n",
    "vec_env = VecVideoRecorder(vec_env, \"logs/videos/\",\n",
    "                       record_video_trigger=lambda x: x == 0, video_length=1000,\n",
    "                       name_prefix=f\"ppo-agent-CartPole-v1\")\n",
    "\n",
    "vec_env.reset()\n",
    "for i in range(1000 + 1):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")\n",
    "\n",
    "    if done: \n",
    "        break;\n",
    "vec_env.close()\n",
    "\n",
    "#Hack to close window\n",
    "import cv2\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9f585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"test\" controls>\n",
       "        <source src=\"logs/videos/ppo-agent-CartPole-v1-step-0-to-step-1000.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" controls>\n",
    "        <source src=\"logs/videos/ppo-agent-CartPole-v1-step-0-to-step-1000.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c609e5",
   "metadata": {},
   "source": [
    "<h1> Further Investigation on effectiveness of PPO</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34cb053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 5000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.7     |\n",
      "|    ep_rew_mean     | 23.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 734      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.4        |\n",
      "|    ep_rew_mean          | 28.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663777 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.00143     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.3        |\n",
      "|    ep_rew_mean          | 35.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 541         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009172572 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.0501      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "Training model for 5000 timesteps completed\n",
      "Average score for 5000 timesteps is  64.39\n",
      "Training model for 10000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.5     |\n",
      "|    ep_rew_mean     | 21.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 596      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.2        |\n",
      "|    ep_rew_mean          | 27.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008381102 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.00455    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.59        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.6        |\n",
      "|    ep_rew_mean          | 33.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009032115 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | 0.0884      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44          |\n",
      "|    ep_rew_mean          | 44          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011463118 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.63       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 58.4        |\n",
      "|    ep_rew_mean          | 58.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008573201 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "Training model for 10000 timesteps completed\n",
      "Average score for 10000 timesteps is  149.41\n",
      "Training model for 15000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.2     |\n",
      "|    ep_rew_mean     | 20.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 546      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 26.4       |\n",
      "|    ep_rew_mean          | 26.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 366        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00944828 |\n",
      "|    clip_fraction        | 0.0929     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.000408   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.14       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 43.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 35.8       |\n",
      "|    ep_rew_mean          | 35.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 312        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01367666 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.67      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.4        |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    value_loss           | 34.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.1        |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009774867 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 65           |\n",
      "|    ep_rew_mean          | 65           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081750285 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.615       |\n",
      "|    explained_variance   | 0.27         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 61.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82          |\n",
      "|    ep_rew_mean          | 82          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008294507 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98           |\n",
      "|    ep_rew_mean          | 98           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080679245 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    value_loss           | 55.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 116         |\n",
      "|    ep_rew_mean          | 116         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005997108 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.43        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "Training model for 15000 timesteps completed\n",
      "Average score for 15000 timesteps is  389.43\n",
      "Training model for 20000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.4     |\n",
      "|    ep_rew_mean     | 21.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 581      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.1        |\n",
      "|    ep_rew_mean          | 26.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008559987 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00561    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.64        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.9        |\n",
      "|    ep_rew_mean          | 36.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 378         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010393176 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.0908      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.3        |\n",
      "|    ep_rew_mean          | 48.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009652624 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.1         |\n",
      "|    ep_rew_mean          | 62.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 352          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077364277 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.6         |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    value_loss           | 66           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 343         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008757476 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 68.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.2         |\n",
      "|    ep_rew_mean          | 94.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056742197 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069811847 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.07         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00939     |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006106559 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.571      |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 144         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008385962 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "Training model for 20000 timesteps completed\n",
      "Average score for 20000 timesteps is  344.11\n",
      "Training model for 25000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.1     |\n",
      "|    ep_rew_mean     | 21.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 607      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.6        |\n",
      "|    ep_rew_mean          | 24.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008217831 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.00471     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.8        |\n",
      "|    ep_rew_mean          | 33.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 378         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011001229 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.0737      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.6        |\n",
      "|    ep_rew_mean          | 45.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009354775 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.627      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.5        |\n",
      "|    ep_rew_mean          | 59.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007794831 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.601      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.3        |\n",
      "|    ep_rew_mean          | 76.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 338         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009358578 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.1         |\n",
      "|    ep_rew_mean          | 92.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073442655 |\n",
      "|    clip_fraction        | 0.0918       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.594       |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005291168 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 126         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008337195 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.575      |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 146          |\n",
      "|    ep_rew_mean          | 146          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023987342 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.578       |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 166          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 330          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045399573 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.5          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 182          |\n",
      "|    ep_rew_mean          | 182          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 328          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047087604 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 201          |\n",
      "|    ep_rew_mean          | 201          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 329          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023676837 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 55.9         |\n",
      "------------------------------------------\n",
      "Training model for 25000 timesteps completed\n",
      "Average score for 25000 timesteps is  427.96\n",
      "Training model for 30000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.3     |\n",
      "|    ep_rew_mean     | 21.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 622      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27          |\n",
      "|    ep_rew_mean          | 27          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008596314 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | -0.00162    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | 34.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011438889 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 46.1         |\n",
      "|    ep_rew_mean          | 46.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072973208 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 52.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 61.5        |\n",
      "|    ep_rew_mean          | 61.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005736402 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74          |\n",
      "|    ep_rew_mean          | 74          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008145196 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "avg_score_per_dif_timesteps = []\n",
    "episodes = 100\n",
    "vec_env = model.get_env()\n",
    "\n",
    "for i in range(5000, 35000, 5000):\n",
    "    print(\"Training model for\", i, \"timesteps started\")\n",
    "    model = PPO('MlpPolicy', env, verbose=1)\n",
    "    model.learn(total_timesteps=i)\n",
    "    print(\"Training model for\", i, \"timesteps completed\")\n",
    "    \n",
    "    sum_episode_scores = []  # Reset sum_episode_scores for each timestep iteration\n",
    "    for episode in range(1, episodes + 1):\n",
    "        score = 0\n",
    "        obs = vec_env.reset()  # Reset the environment before each episode\n",
    "\n",
    "        while True:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, info = vec_env.step(action)\n",
    "            score += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Convert score to scalar value if it's a NumPy array\n",
    "        if isinstance(score, np.ndarray):\n",
    "            score = score.item()\n",
    "\n",
    "        sum_episode_scores.append(score)\n",
    "\n",
    "    # Calculate average score for the current timestep iteration\n",
    "    if sum_episode_scores:\n",
    "        avg = sum(sum_episode_scores) / len(sum_episode_scores)\n",
    "    else:\n",
    "        avg = 0\n",
    "\n",
    "    print(\"Average score for\", i, \"timesteps is \", round(avg, 2))\n",
    "    avg_score_per_dif_timesteps.append(round(avg, 2))\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_score_per_dif_timesteps)\n",
    "x_labels = ['5000', '10000', '15000', '20000', '25000', '30000']\n",
    "plt.title(\"Average reward per 100 episode for each X timesteps used for training\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.xticks(range(len(x_labels)), x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64842c39",
   "metadata": {},
   "source": [
    "From the graph, it can be observed that PPO achieves relatively good reward scores of above 300, typically within the range of 15000 to 25000 steps, achieving  a near perfect performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
