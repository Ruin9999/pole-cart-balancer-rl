{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb7ebc7",
   "metadata": {},
   "source": [
    "<h1> Project Description </h1>\n",
    "\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart. In this project, you will need to develop a Reinforcement Learning (RL) agent. The trained agent makes the decision to push the cart to the left or right based on the cart position, velocity, and the pole angle, angular velocity.   \n",
    "  \n",
    "After some research, we decided on two different algorithms for this problem, the <span style=\"color:blue; font-weight:bold\"> Deep Q-learning Neural Network </span> and the <span style=\"color:blue; font-weight:bold\"> Proximial Policy Optimization </span>\n",
    "\n",
    "We present our findings here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d6130",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e14be",
   "metadata": {},
   "source": [
    "After some research, we came to the conclusion of 2 different algorithms for this problem, a <span style=\"color:blue; font-weight:bold\"> Deep Q-Learning Neural Network </span> and <span style=\"color:blue; font-weight:bold\"> Proximial Oplicy Optimization </span>\n",
    "\n",
    "These are the differences between the two reinforcement learning algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561edd4",
   "metadata": {},
   "source": [
    "<b>Deep Q-learning Neural Network </b> :   \n",
    "The Deep Q-learning Neural Netork is value based reinforcement learning algorithm that is similar to the Q-learning algorithm. However, instead of using a formula to greedily find the Q-function of the environment, DQN tries to approximate the Q-function using neural networks.\n",
    "\n",
    "DQN utilizes <b style=\"color:blue;\">Experience Replaying</b> and <b style=\"color:blue;\"> Fixed Q Targets </b> to stabilize its training along with the Q-learning update formula to approximate the Q-function.   \n",
    "\n",
    "The Q-learning update rule :\n",
    "\n",
    "<br/>\n",
    "$$ L_i(\\theta_i) = \\mathbb{E}_{s,a,s',r \\sim D} \\left[ \\left( r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s, a; \\theta_i) \\right)^2 \\right]\n",
    " $$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde690da",
   "metadata": {},
   "source": [
    "<b> Proximial Policy Optimization </b> :    \n",
    "Proximial Policy Optimization is a policy based reinforcement learning algorithm. PPO is a successor to the famous <b style=\"color:blue\">Trust Region Policy Optimization (TRPO) </b>, made by OpenAI to overcome its limitations.\n",
    "\n",
    "PPO tries to optimize the policy function without explicitly estimating the v value function. PPO is designed to not only be more <b style=\"color:blue;\">sample-efficient </b>, it is also more <b style=\"color:blue;\">stable during training</b>.\n",
    "\n",
    "PPO tries to optimize the policy using this function:     \n",
    "<br/>\n",
    "$$ L_t^{CLIP+VF+S}(\\theta) = \\hat{\\mathbb{E}}_t \\left[ L_t^{CLIP}(\\theta) - c_1 L_t^{VF}(\\theta) + c_2 S[\\pi_\\theta](s_t) \\right]\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5c73d",
   "metadata": {},
   "source": [
    "Choice of Reinforcement Learning Algorithm: <b>PPO</b>\n",
    "\n",
    "- In terms of Continuous Action Space, PPO is more suited for continuous action spaces, like controlling the movement of the cart on a horizontal axis. It <b style=\"color:blue;\">eases the task where actions are continuous</b>.\n",
    "- It is <b style=\"color:blue;\">more sample-efficient</b>. As exploration and learning from limited spaces are crucial in the pole cart balancing task, the efficiency from PPO can lead to faster convergence and better performance.\n",
    "- Since tasks like pole cart balancing requires precise and consistent control to maintain balance, PPO is designed to be <b style=\"color:blue\">more stable during training</b>.\n",
    "- PPO's adaptive step sizes and clipped surrogate objective makes it <b style=\"color:blue\">more adaptable to different environments</b>. The flexibility benefits the fine-tuning of the balancing behaviour of the cart in response to the changes in environment and task requirements.\n",
    "\n",
    "- While both Deep Q-Learning and PPO have its strengths and weakness, PPO's suitability for continuous action spaces, sample efficiency, adaptability and stability makes it a better choice for the pole cart balancing task when making a decision in terms of the Reinforcement Learning Algorithm used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198126b",
   "metadata": {},
   "source": [
    "<h1> Installing dependencies </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc27df65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\limya\\anaconda3\\lib\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium) (4.10.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.8.0)\n",
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\limya\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.21.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (9.2.0)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.16.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: shimmy[atari]~=1.3.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pygame in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.5.2)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.9.0.80)\n",
      "Requirement already satisfied: tqdm in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: rich in c:\\users\\limya\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\limya\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.28.1)\n",
      "Requirement already satisfied: click in c:\\users\\limya\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\limya\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from shimmy[atari]~=1.3.0->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (63.4.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.62.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\limya\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\limya\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\limya\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2022.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\limya\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.10.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.17.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\limya\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\limya\\anaconda3\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13->stable-baselines3[extra]) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2022.9.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\limya\\anaconda3\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b4f02",
   "metadata": {},
   "source": [
    "<h1> Creating the gym environment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff789ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b731552",
   "metadata": {},
   "source": [
    "We use ```gym.make()``` to create a simulation of the environment.   \n",
    "The environment has <span style=\"color: blue; font-weight: bold;\">4 actions</span> that we can take and <span style=\"color: blue;font-weight: bold;\">2 distinct observations</span> for our agent.   \n",
    "\n",
    "Observation Space contains ```[base position, base velocity, pole angle, pole angular velocity]```.    \n",
    "Action Space contains ```[left, right]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc3c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space : 4\n",
      "Action Space : 2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "print(\"Observation Space : {}\".format(env.observation_space.shape[0]))\n",
    "print(\"Action Space : {}\".format(env.action_space.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8846e51",
   "metadata": {},
   "source": [
    "To test our envrionment, we will iterate through 10 episodes.   \n",
    "Taking random actions i.e ```[left, right]``` we render the environment until the episode length reaches ```500``` or the pole angular velocity goes beyond the bounds of ``` ~ -0.418 rad (-24°) and ~ 0.418 rad (24°)```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebc0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 score : 19.0\n",
      "Episode 2 score : 29.0\n",
      "Episode 3 score : 12.0\n",
      "Episode 4 score : 13.0\n",
      "Episode 5 score : 15.0\n",
      "Episode 6 score : 16.0\n",
      "Episode 7 score : 13.0\n",
      "Episode 8 score : 14.0\n",
      "Episode 9 score : 33.0\n",
      "Episode 10 score : 15.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "env.reset()\n",
    "\n",
    "for episode in range (1, episodes + 1):\n",
    "    observation = env.reset()\n",
    "    score = 0\n",
    "    \n",
    "    while True:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward;\n",
    "        if terminated or truncated:\n",
    "            break;\n",
    "     \n",
    "    print(\"Episode {} score : {}\".format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144789b",
   "metadata": {},
   "source": [
    "<h1> Building and Training the model </h1>\n",
    "<p>From the Stable Baselines library, we will be using the PPO (Proximal Policy Optimization) algorithm. MlpPolicy which refers to Multi-Layer Perceptron Policy is used as it is a neural network policy that contains multiple layers that is suitable for discrete action spaces and is able to handle a wide range of environments.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63f9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13a93ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745033ea",
   "metadata": {},
   "source": [
    "To train the model, we will conduct training over 30,000 steps. From the output, we will examine <b stlye=\"color:blu>ep_len_mean</b>,<b>ep_rew_mean</b> and <b>explained_variance</b>. A higher value for <b>ep_len_mean</b> indicates a more successful average duration of episodes. Similarly, a higher <b>ep_rew_mean</b> signifies a better average reward for each episode. For <b>explained_variance</b>, we aim for a higher value closer to 1, as it indicates more accurate predictions. We chose 30,000 steps because it yields the best learning value output after multiple training sessions, allowing the agent to interact more effectively with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd467a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | 23.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 1018     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.4        |\n",
      "|    ep_rew_mean          | 27.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815188 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -1.62e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.4        |\n",
      "|    ep_rew_mean          | 33.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009371186 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.671      |\n",
      "|    explained_variance   | 0.0649      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.5        |\n",
      "|    ep_rew_mean          | 44.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008501918 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.3        |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010485286 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 72.5         |\n",
      "|    ep_rew_mean          | 72.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090320455 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.593       |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    value_loss           | 58.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88.5        |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010919424 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.72        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 108          |\n",
      "|    ep_rew_mean          | 108          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041972753 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 123         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 543         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012682274 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 145         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010033406 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.54        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 161          |\n",
      "|    ep_rew_mean          | 161          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022742064 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.8         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 181         |\n",
      "|    ep_rew_mean          | 181         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006765389 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.0135      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 200          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 527          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030335968 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.16         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 8.45         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 222          |\n",
      "|    ep_rew_mean          | 222          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 526          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054327194 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.975        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    value_loss           | 4.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 238          |\n",
      "|    ep_rew_mean          | 238          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023498933 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.157        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 2.07         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1fd16c6fdf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.learn(total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd0cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join(\"Saved Models\", \"PPO\")\n",
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b25d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 360.969944}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.99554986,  1.0812082 ,  0.01011018, -0.16924387], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 368.429144}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.22665766, -1.1574059 , -0.02053004,  0.6879047 ], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 375.798595}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.60893404,  1.1038226 , -0.01480056, -0.41134575], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 383.333144}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.49735352, -0.7525714 ,  0.05683759,  0.3956153 ], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 404.0, 'l': 404, 't': 389.430588}, 'TimeLimit.truncated': False, 'terminal_observation': array([-1.5256609 , -0.7819538 ,  0.21072432,  0.30272806], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 396.971379}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.27011082, -0.42173183, -0.03345193,  0.47601503], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 404.245269}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.87837934,  0.33002433,  0.01670614, -0.26675424], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 411.668222}, 'TimeLimit.truncated': True, 'terminal_observation': array([ 0.12746295, -0.01988972, -0.14011367, -0.04846017], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 419.341546}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.2815966 , -0.01285015, -0.02028362, -0.04424476], dtype=float32)}]\n",
      "Info:  [{'episode': {'r': 500.0, 'l': 500, 't': 426.835778}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.4339896 ,  0.04998778, -0.03905358, -0.08857926], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "vec_env = model.get_env()\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = vec_env.reset()\n",
    "    while True:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "        vec_env.render(\"human\")\n",
    "        if done:\n",
    "            print(\"Info: \", info)\n",
    "            break;\n",
    "\n",
    "#Hack to close window\n",
    "import cv2\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d7600",
   "metadata": {},
   "source": [
    "<h1> Task 1 : Develop an RL agent </h1>\n",
    "<b> For this task, we have to demonstrate the correctness of the implementation through sampling a random state from the environment together with an agent input and output a chosen action on whether it is 0(left) or 1(right). </b>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc04d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "model = PPO.load(\"Saved Models\\PPO\", env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb9328",
   "metadata": {},
   "source": [
    "<p> A new gym environment is created and rendered with rgb_array to visualize the environment. We will use a pre-trained PPO model to train the cartPole environment. A vectorized environment is obtained from the PPO model, enabling the execution of multiple environments simultanteously, each operating independently. This approach significantly accelerates the training process.<br/><br/>\n",
    "After acquiring the environment, we rest the vectorized environment to its initial observation state. Using this observation, the PPO model predicts the first action based on the loaded model. The output displays the observation and the predicted action. In this case, applying a force to the left (0) is intended to balance the pole, as determined by the observation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514183e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation : [[ 0.01237707 -0.00265931 -0.04915024  0.01335459]]\n",
      "Action : [1]\n"
     ]
    }
   ],
   "source": [
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "action = model.predict(obs)[0]\n",
    "\n",
    "print(\"Observation : {}\".format(obs))\n",
    "print(\"Action : {}\".format(action))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d393e",
   "metadata": {},
   "source": [
    "<h1> Task 2 : Demonstrate the effectiveness of the RL agent </h1>\n",
    "<br/>\n",
    "<b>For this task, we have to run for 100 episodes, resetting each environment at the beginning and plot the cummulative reward against all episodes. Print the average reward over the 100 episodes.</b>\n",
    "<br/><br/>\n",
    "Using the vectorized environment, we will iterate through 100 episodes. For each episode, the trained learning model will predict an action based on a specific observation. Taking the predicted action for each step, the environment returns four values: new observation, obtained reward, an indicator of whether the episode is completed, and additional information ('info') from that step. A reward will be given after each step and at the end of each episode, we would append the cummulative rewards into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423f6e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 ;   Score: [500.]\n",
      "Episode: 2 ;   Score: [500.]\n",
      "Episode: 3 ;   Score: [500.]\n",
      "Episode: 4 ;   Score: [500.]\n",
      "Episode: 5 ;   Score: [500.]\n",
      "Episode: 6 ;   Score: [500.]\n",
      "Episode: 7 ;   Score: [500.]\n",
      "Episode: 8 ;   Score: [500.]\n",
      "Episode: 9 ;   Score: [500.]\n",
      "Episode: 10 ;   Score: [500.]\n",
      "Episode: 11 ;   Score: [500.]\n",
      "Episode: 12 ;   Score: [500.]\n",
      "Episode: 13 ;   Score: [500.]\n",
      "Episode: 14 ;   Score: [500.]\n",
      "Episode: 15 ;   Score: [500.]\n",
      "Episode: 16 ;   Score: [500.]\n",
      "Episode: 17 ;   Score: [500.]\n",
      "Episode: 18 ;   Score: [500.]\n",
      "Episode: 19 ;   Score: [500.]\n",
      "Episode: 20 ;   Score: [500.]\n",
      "Episode: 21 ;   Score: [500.]\n",
      "Episode: 22 ;   Score: [500.]\n",
      "Episode: 23 ;   Score: [500.]\n",
      "Episode: 24 ;   Score: [500.]\n",
      "Episode: 25 ;   Score: [500.]\n",
      "Episode: 26 ;   Score: [500.]\n",
      "Episode: 27 ;   Score: [500.]\n",
      "Episode: 28 ;   Score: [500.]\n",
      "Episode: 29 ;   Score: [500.]\n",
      "Episode: 30 ;   Score: [500.]\n",
      "Episode: 31 ;   Score: [500.]\n",
      "Episode: 32 ;   Score: [500.]\n",
      "Episode: 33 ;   Score: [500.]\n",
      "Episode: 34 ;   Score: [500.]\n",
      "Episode: 35 ;   Score: [500.]\n",
      "Episode: 36 ;   Score: [500.]\n",
      "Episode: 37 ;   Score: [500.]\n",
      "Episode: 38 ;   Score: [500.]\n",
      "Episode: 39 ;   Score: [500.]\n",
      "Episode: 40 ;   Score: [500.]\n",
      "Episode: 41 ;   Score: [500.]\n",
      "Episode: 42 ;   Score: [500.]\n",
      "Episode: 43 ;   Score: [500.]\n",
      "Episode: 44 ;   Score: [500.]\n",
      "Episode: 45 ;   Score: [500.]\n",
      "Episode: 46 ;   Score: [500.]\n",
      "Episode: 47 ;   Score: [500.]\n",
      "Episode: 48 ;   Score: [500.]\n",
      "Episode: 49 ;   Score: [500.]\n",
      "Episode: 50 ;   Score: [500.]\n",
      "Episode: 51 ;   Score: [500.]\n",
      "Episode: 52 ;   Score: [500.]\n",
      "Episode: 53 ;   Score: [500.]\n",
      "Episode: 54 ;   Score: [500.]\n",
      "Episode: 55 ;   Score: [500.]\n",
      "Episode: 56 ;   Score: [500.]\n",
      "Episode: 57 ;   Score: [500.]\n",
      "Episode: 58 ;   Score: [500.]\n",
      "Episode: 59 ;   Score: [500.]\n",
      "Episode: 60 ;   Score: [500.]\n",
      "Episode: 61 ;   Score: [500.]\n",
      "Episode: 62 ;   Score: [500.]\n",
      "Episode: 63 ;   Score: [500.]\n",
      "Episode: 64 ;   Score: [500.]\n",
      "Episode: 65 ;   Score: [500.]\n",
      "Episode: 66 ;   Score: [500.]\n",
      "Episode: 67 ;   Score: [500.]\n",
      "Episode: 68 ;   Score: [500.]\n",
      "Episode: 69 ;   Score: [500.]\n",
      "Episode: 70 ;   Score: [500.]\n",
      "Episode: 71 ;   Score: [500.]\n",
      "Episode: 72 ;   Score: [500.]\n",
      "Episode: 73 ;   Score: [500.]\n",
      "Episode: 74 ;   Score: [500.]\n",
      "Episode: 75 ;   Score: [500.]\n",
      "Episode: 76 ;   Score: [500.]\n",
      "Episode: 77 ;   Score: [500.]\n",
      "Episode: 78 ;   Score: [500.]\n",
      "Episode: 79 ;   Score: [500.]\n",
      "Episode: 80 ;   Score: [500.]\n",
      "Episode: 81 ;   Score: [500.]\n",
      "Episode: 82 ;   Score: [500.]\n",
      "Episode: 83 ;   Score: [500.]\n",
      "Episode: 84 ;   Score: [500.]\n",
      "Episode: 85 ;   Score: [500.]\n",
      "Episode: 86 ;   Score: [500.]\n",
      "Episode: 87 ;   Score: [500.]\n",
      "Episode: 88 ;   Score: [500.]\n",
      "Episode: 89 ;   Score: [500.]\n",
      "Episode: 90 ;   Score: [500.]\n",
      "Episode: 91 ;   Score: [500.]\n",
      "Episode: 92 ;   Score: [500.]\n",
      "Episode: 93 ;   Score: [500.]\n",
      "Episode: 94 ;   Score: [500.]\n",
      "Episode: 95 ;   Score: [500.]\n",
      "Episode: 96 ;   Score: [500.]\n",
      "Episode: 97 ;   Score: [500.]\n",
      "Episode: 98 ;   Score: [500.]\n",
      "Episode: 99 ;   Score: [500.]\n",
      "Episode: 100 ;   Score: [500.]\n",
      "[array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32), array([500.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "episodes = 100\n",
    "vec_env = model.get_env()\n",
    "cumilative_rewards = []\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    score = 0\n",
    "    obs = vec_env.reset()\n",
    "    \n",
    "    while True:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "        if done:\n",
    "            break;\n",
    "    print('Episode:', episode, ';   Score:', score)\n",
    "    cumilative_rewards.append(score)\n",
    "\n",
    "print(cumilative_rewards)\n",
    "\n",
    "#Hack to close window\n",
    "import cv2\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef050f",
   "metadata": {},
   "source": [
    "<h3> Plotting our rewards </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "593b49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b27574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the cumulative rewards\n",
    "plt.plot(range(1, episodes + 1), cumilative_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Cumulative Rewards Over Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49b8dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cummulative reward:  [500.]\n"
     ]
    }
   ],
   "source": [
    "mean = sum(cumilative_rewards) / len(cumilative_rewards)\n",
    "print(\"Average cummulative reward: \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c27bca",
   "metadata": {},
   "source": [
    "From the results in the cummulative graph, we could see that for every episode, the rewards are consistent with an average value of around 490-500. This indicated that the RL agent has successfully learned the PPO to effectively balance the pole on the cart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c8b38",
   "metadata": {},
   "source": [
    "<h1> Task 3: Render an episode played by RL agent </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3a3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "obs = vec_env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")\n",
    "\n",
    "    if done: \n",
    "        break;\n",
    "\n",
    "#Hack to close window\n",
    "import cv2\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c609e5",
   "metadata": {},
   "source": [
    "<h1> Further Investigation on effectiveness of PPO</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f34cb053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 5000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.7     |\n",
      "|    ep_rew_mean     | 21.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 1000     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 29.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 672         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008006221 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.000747    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.1         |\n",
      "|    ep_rew_mean          | 40.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 599          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096665295 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.67        |\n",
      "|    explained_variance   | 0.1          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.6          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0193      |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "Training model for 5000 timesteps completed\n",
      "Average score for 5000 timesteps is  64.95\n",
      "Training model for 10000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.3     |\n",
      "|    ep_rew_mean     | 21.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 955      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | 28.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007818445 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.0065     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.84        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.5        |\n",
      "|    ep_rew_mean          | 37.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008399416 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.0718      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 48.7       |\n",
      "|    ep_rew_mean          | 48.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 559        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00860614 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.624     |\n",
      "|    explained_variance   | 0.254      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    value_loss           | 56.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 65           |\n",
      "|    ep_rew_mean          | 65           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117503395 |\n",
      "|    clip_fraction        | 0.0955       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.598       |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0203      |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "Training model for 10000 timesteps completed\n",
      "Average score for 10000 timesteps is  131.85\n",
      "Training model for 15000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.2     |\n",
      "|    ep_rew_mean     | 23.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 1004     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.8        |\n",
      "|    ep_rew_mean          | 25.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009008255 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.0024      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.15        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.3        |\n",
      "|    ep_rew_mean          | 35.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436417 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.56        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.4        |\n",
      "|    ep_rew_mean          | 46.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006547833 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 55.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61.8         |\n",
      "|    ep_rew_mean          | 61.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 577          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070233177 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.616       |\n",
      "|    explained_variance   | 0.328        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 79.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007267268 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.607      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.7         |\n",
      "|    ep_rew_mean          | 94.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053944504 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.594       |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00946     |\n",
      "|    value_loss           | 54.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 555         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005239291 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "Training model for 15000 timesteps completed\n",
      "Average score for 15000 timesteps is  284.12\n",
      "Training model for 20000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.7     |\n",
      "|    ep_rew_mean     | 22.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 1014     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.8        |\n",
      "|    ep_rew_mean          | 25.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009086791 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.000195    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.4         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.4        |\n",
      "|    ep_rew_mean          | 33.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010895368 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.0789      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 47          |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008209388 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.3         |\n",
      "|    ep_rew_mean          | 62.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075188335 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.606       |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    value_loss           | 65.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 76.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007124233 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 71.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.1        |\n",
      "|    ep_rew_mean          | 92.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005272745 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032359748 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 127          |\n",
      "|    ep_rew_mean          | 127          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 534          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040123668 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 145         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003903313 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.572      |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.74        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "Training model for 20000 timesteps completed\n",
      "Average score for 20000 timesteps is  385.42\n",
      "Training model for 25000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.3     |\n",
      "|    ep_rew_mean     | 23.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 988      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.6        |\n",
      "|    ep_rew_mean          | 27.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008359242 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00108    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.1        |\n",
      "|    ep_rew_mean          | 36.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009840347 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.9        |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007855208 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.643      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 58.2       |\n",
      "|    ep_rew_mean          | 58.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 575        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01304786 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.592     |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 35.4       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    value_loss           | 67         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.8        |\n",
      "|    ep_rew_mean          | 74.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008585886 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.58       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.7        |\n",
      "|    ep_rew_mean          | 92.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007041647 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.572      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 553         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004519431 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.72        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 121         |\n",
      "|    ep_rew_mean          | 121         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010181086 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 138        |\n",
      "|    ep_rew_mean          | 138        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 546        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00590228 |\n",
      "|    clip_fraction        | 0.0381     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.564     |\n",
      "|    explained_variance   | 0.674      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.7       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00572   |\n",
      "|    value_loss           | 58.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 158         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 543         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006799369 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.37        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006612137 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 194          |\n",
      "|    ep_rew_mean          | 194          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 537          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052710595 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | 0.000491     |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "Training model for 25000 timesteps completed\n",
      "Average score for 25000 timesteps is  483.19\n",
      "Training model for 30000 timesteps started\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | 22.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 940      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 29.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 637         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008619085 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.00116     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.55        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.5        |\n",
      "|    ep_rew_mean          | 38.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009432944 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.0801      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.6        |\n",
      "|    ep_rew_mean          | 50.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008886766 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.4        |\n",
      "|    ep_rew_mean          | 65.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006569388 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.8       |\n",
      "|    ep_rew_mean          | 79.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01167215 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.591     |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    value_loss           | 57.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.2        |\n",
      "|    ep_rew_mean          | 94.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010215791 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.565      |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005187769 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.574      |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006151883 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005581375 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010478549 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 181          |\n",
      "|    ep_rew_mean          | 181          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047179507 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.129        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000818    |\n",
      "|    value_loss           | 6.7          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 200         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004580266 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.78        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 215         |\n",
      "|    ep_rew_mean          | 215         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015136067 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 235         |\n",
      "|    ep_rew_mean          | 235         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009046497 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.53       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    value_loss           | 1.79        |\n",
      "-----------------------------------------\n",
      "Training model for 30000 timesteps completed\n",
      "Average score for 30000 timesteps is  500.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "avg_score_per_dif_timesteps = []\n",
    "episodes = 100\n",
    "vec_env = model.get_env()\n",
    "\n",
    "for i in range(5000, 35000, 5000):\n",
    "    print(\"Training model for\", i, \"timesteps started\")\n",
    "    model = PPO('MlpPolicy', env, verbose=1)\n",
    "    model.learn(total_timesteps=i)\n",
    "    print(\"Training model for\", i, \"timesteps completed\")\n",
    "    \n",
    "    sum_episode_scores = []  # Reset sum_episode_scores for each timestep iteration\n",
    "    for episode in range(1, episodes + 1):\n",
    "        score = 0\n",
    "        obs = vec_env.reset()  # Reset the environment before each episode\n",
    "\n",
    "        while True:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, info = vec_env.step(action)\n",
    "            score += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Convert score to scalar value if it's a NumPy array\n",
    "        if isinstance(score, np.ndarray):\n",
    "            score = score.item()\n",
    "\n",
    "        sum_episode_scores.append(score)\n",
    "\n",
    "    # Calculate average score for the current timestep iteration\n",
    "    if sum_episode_scores:\n",
    "        avg = sum(sum_episode_scores) / len(sum_episode_scores)\n",
    "    else:\n",
    "        avg = 0\n",
    "\n",
    "    print(\"Average score for\", i, \"timesteps is \", round(avg, 2))\n",
    "    avg_score_per_dif_timesteps.append(round(avg, 2))\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48ba2f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_score_per_dif_timesteps)\n",
    "x_labels = ['5000', '10000', '15000', '20000', '25000', '30000']\n",
    "plt.title(\"Average reward per 100 episode for each X timesteps used for training\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.xticks(range(len(x_labels)), x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64842c39",
   "metadata": {},
   "source": [
    "From the graph, it can be observed that PPO achieves relatively good reward scores of above 300, typically within the range of 15000 to 25000 steps, achieving  a near perfect performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
